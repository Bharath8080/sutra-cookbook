{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPmtjCmHPFlR"
      },
      "source": [
        "<div style=\"display: flex; align-items: center; gap: 40px;\">\n",
        "\n",
        "<img src=\"https://play-lh.googleusercontent.com/_O9p4Z4yucA2NLmZBu9mTJCuBwXeT9NcbtrDN6I8gKlkIPRySV0adOmbyipjSj9Gew\" width=\"130\">\n",
        "<img src=\"https://avatars.githubusercontent.com/u/209155962?s=200&v=4\" width=\"130\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<div>\n",
        "  <h2>SUTRA by TWO Platforms</h2>\n",
        "  <p>SUTRA is a family of large multi-lingual language (LMLMs) models pioneered by Two Platforms. SUTRA’s dual-transformer approach extends the power of both MoE and Dense AI language model architectures, delivering cost-efficient multilingual capabilities for over 50+ languages. It powers scalable AI applications for conversation, search, and advanced reasoning, ensuring high-performance across diverse languages, domains and applications.</p>\n",
        "\n",
        "</div>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1JEs8bnJxjdS_t-M3IVek_841I6FG4ABZ?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdkxiWb3AUl9"
      },
      "source": [
        "# SUTRA with Strands Agents SDK\n",
        "\n",
        "Strands Agents is a simple yet powerful SDK that takes a model-driven approach to building and running AI agents. From simple conversational assistants to complex autonomous workflows, from local development to production deployment, Strands Agents scales with your needs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfO3wEKlAUl_"
      },
      "source": [
        "## Setup and Installation\n",
        "\n",
        "First, let's install the required packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kaZHGLhAUmA"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install strands-agents strands-agents[litellm] strands-agents-tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aniyo7sfA3Ix"
      },
      "source": [
        " ## Step 2: Authentication\n",
        "\n",
        "SUTRA uses API keys for authentication. In Google Colab, we recommend using the `userdata` feature to securely store your API key.\n",
        "\n",
        "### Setting up your API key in Colab:\n",
        "\n",
        "1. Click on the 🔑 icon in the left sidebar\n",
        "2. Add a new secret with the name \"SUTRA_API_KEY\" and your API key as the value\n",
        "\n",
        "Then run the cell below to access your API key:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VQc0p3lA4Nz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set the API key from Colab secrets\n",
        "os.environ[\"SUTRA_API_KEY\"] = userdata.get(\"SUTRA_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HdjZ7DiAUmA"
      },
      "source": [
        "## Setting Up the Sutra v2 Model with LiteLLM\n",
        "\n",
        "We'll use LiteLLM to connect to the Sutra v2 model. This provides a unified interface for working with different LLM providers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jwo5gg5AUmA"
      },
      "outputs": [],
      "source": [
        "from strands import Agent\n",
        "from strands.models.litellm import LiteLLMModel\n",
        "import os\n",
        "\n",
        "# Initialize the LiteLLM model for Sutra v2\n",
        "model = LiteLLMModel(\n",
        "    client_args={\n",
        "        \"api_key\": os.environ[\"SUTRA_API_KEY\"],\n",
        "        \"base_url\": \"https://api.two.ai/v2\"\n",
        "    },\n",
        "    model_id=\"openai/sutra-v2\",\n",
        "    params={\n",
        "        \"max_tokens\": 1000,\n",
        "        \"temperature\": 0.7,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YVYeUG5AUmA"
      },
      "source": [
        "## Creating a Basic Strands Agent\n",
        "\n",
        "Now, let's create a basic Strands agent using our Sutra v2 model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ShlP7Z8AUmA"
      },
      "outputs": [],
      "source": [
        "# Create a basic agent with no tools\n",
        "basic_agent = Agent(model=model)\n",
        "\n",
        "# Test the agent with a simple query\n",
        "response = basic_agent(\"What are the key features of Sutra v2?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBoNvozFAUmA"
      },
      "source": [
        "## Importing Tools from strands-agents-tools\n",
        "\n",
        "Let's import various tools from the strands-agents-tools library that we'll use with our agent.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i22VntAHAUmA"
      },
      "outputs": [],
      "source": [
        "# Import tools from strands_tools\n",
        "from strands_tools import (\n",
        "    calculator,\n",
        "    file_read,\n",
        "    file_write,\n",
        "    editor,\n",
        "    shell,\n",
        "    http_request,\n",
        "    python_repl,\n",
        "    current_time,\n",
        "    think\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzXKd2GlAUmA"
      },
      "source": [
        "## Creating a Basic Strands Agent with Calculator Tool\n",
        "\n",
        "Let's start with a simple example using the calculator tool, which was in the original code snippet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G72xZg2vAUmA"
      },
      "outputs": [],
      "source": [
        "# Create a basic agent with calculator tool\n",
        "calculator_agent = Agent(model=model, tools=[calculator])\n",
        "\n",
        "# Test the agent with a math problem\n",
        "math_query = \"What is the square root of (144 * 25) divided by 2?\"\n",
        "math_response = calculator_agent(math_query)\n",
        "print(math_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Keh_hEtxAUmA"
      },
      "source": [
        "## Using the current_time Tool\n",
        "\n",
        "The current_time tool allows agents to get the current time in different timezones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ul1tTer2GWvY",
        "outputId": "fbdc2f0b-c15d-481e-a63d-b8bf582ec81d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Local time: {'toolUseId': 'tooluse_current_time_852155718', 'status': 'success', 'content': [{'text': '2025-05-21T09:13:39.593160+00:00'}]}\n",
            "India Standard Time: {'toolUseId': 'tooluse_current_time_565759674', 'status': 'success', 'content': [{'text': '2025-05-21T14:43:39.595674+05:30'}]}\n",
            "Pacific Time: {'toolUseId': 'tooluse_current_time_298829101', 'status': 'success', 'content': [{'text': '2025-05-21T02:13:39.597000-07:00'}]}\n",
            "UTC: {'toolUseId': 'tooluse_current_time_733130084', 'status': 'success', 'content': [{'text': '2025-05-21T09:13:39.597455+00:00'}]}\n"
          ]
        }
      ],
      "source": [
        "# Create an agent with current_time tool\n",
        "time_agent = Agent(model=model, tools=[current_time])\n",
        "\n",
        "# Get the current time in different timezones\n",
        "local_time = time_agent.tool.current_time()\n",
        "print(f\"Local time: {local_time}\")\n",
        "\n",
        "ist_time = time_agent.tool.current_time(timezone=\"Asia/Kolkata\")\n",
        "print(f\"India Standard Time: {ist_time}\")\n",
        "\n",
        "pacific_time = time_agent.tool.current_time(timezone=\"US/Pacific\")\n",
        "print(f\"Pacific Time: {pacific_time}\")\n",
        "\n",
        "utc_time = time_agent.tool.current_time(timezone=\"UTC\")\n",
        "print(f\"UTC: {utc_time}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZr6a0VIJVas"
      },
      "source": [
        "## Creating a Multi-Tool Agent\n",
        "\n",
        "Now, let's create an agent with multiple tools to demonstrate how they can be combined to solve complex tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgCfxA0vJV-m"
      },
      "outputs": [],
      "source": [
        "# Create an agent with multiple tools\n",
        "multi_tool_agent = Agent(\n",
        "    model=model,\n",
        "    tools=[\n",
        "        calculator,\n",
        "        python_repl,\n",
        "        current_time,\n",
        "        think\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu8scqN1Jb5y"
      },
      "source": [
        "## Solving a Complex Task with Multiple Tools\n",
        "\n",
        "Let's use our multi-tool agent to solve a complex task that requires multiple tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrEyIHR5JZjx"
      },
      "outputs": [],
      "source": [
        "# Define a complex task that requires multiple tools\n",
        "complex_task = \"\"\"\n",
        "I need you to help me with the following task:\n",
        "\n",
        "1. Create a Python script that calculates the Fibonacci sequence up to the 20th number\n",
        "2. Save this script to a file named 'fibonacci.py'\n",
        "3. Execute the script and save the output to 'fibonacci_results.txt'\n",
        "4. Calculate the sum of all Fibonacci numbers generated\n",
        "5. Get the current time and append it to the results file\n",
        "6. Finally, display the content of the results file\n",
        "\"\"\"\n",
        "\n",
        "# Let the agent solve the complex task\n",
        "complex_task_response = multi_tool_agent(complex_task)\n",
        "print(complex_task_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMskZCRNAUmB"
      },
      "source": [
        "## Multilingual Capabilities with Sutra v2\n",
        "\n",
        "SUTRA v2 excels at multilingual tasks. Let's test the agent's ability to handle different languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L51FSUA-AUmB"
      },
      "outputs": [],
      "source": [
        "# Test with Hindi query using multiple tools\n",
        "hindi_query = \"\"\"मुझे निम्नलिखित कार्य में मदद करें:\n",
        "1. एक पाइथन स्क्रिप्ट बनाएं जो 1 से 10 तक के वर्गों की गणना करता है\n",
        "2. इस स्क्रिप्ट को 'squares.py' नामक फ़ाइल में सहेजें\n",
        "3. स्क्रिप्ट को निष्पादित करें और परिणाम देखें\n",
        "4. सभी वर्गों का योग गणना करें\"\"\"\n",
        "\n",
        "hindi_response = multi_tool_agent(hindi_query)\n",
        "print(hindi_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UfqtCutJwGx"
      },
      "source": [
        "## Customizing Agent Behavior with System Instructions\n",
        "\n",
        "We can customize agent behavior through system instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvvaWsTaJxqS"
      },
      "outputs": [],
      "source": [
        "# Create an agent with custom system instructions\n",
        "custom_agent = Agent(\n",
        "    model=model,\n",
        "    tools=[calculator, python_repl, think],\n",
        "    system_prompt=\"\"\"You are a helpful AI assistant specialized in educational content.\n",
        "    Always explain your reasoning step by step and provide educational context to your answers.\n",
        "    When using tools, explain why you're using them and what you hope to learn.\n",
        "    Focus on making complex concepts accessible to learners at different levels.\"\"\"\n",
        ")\n",
        "\n",
        "# Test the customized agent\n",
        "education_query = \"Explain the concept of recursion in programming and demonstrate it with a Python example.\"\n",
        "education_response = custom_agent(education_query)\n",
        "print(education_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oI3E5tUAUmB"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we've explored how to use Sutra v2 with LiteLLM provider and Strands agents, incorporating various tools from the strands-agents-tools library. We've covered:\n",
        "\n",
        "1. Setting up the Sutra v2 model with LiteLLM\n",
        "2. Using individual tools like calculator, and Time\n",
        "3. Creating a multi-tool agent capable of solving complex tasks\n",
        "4. Testing multilingual capabilities with Hindi queries\n",
        "5. Customizing agent behavior through system instructions\n",
        "\n",
        "The combination of Sutra v2's powerful language capabilities with Strands' flexible agent framework and rich tool ecosystem enables the development of sophisticated AI applications that can understand user intent, break down complex tasks, and execute them effectively across multiple languages."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
