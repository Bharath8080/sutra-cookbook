{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrl14CoYVTzw"
      },
      "source": [
        "<div style=\"display: flex; align-items: center; gap: 40px;\">\n",
        "\n",
        "<img src=\"https://play-lh.googleusercontent.com/_O9p4Z4yucA2NLmZBu9mTJCuBwXeT9NcbtrDN6I8gKlkIPRySV0adOmbyipjSj9Gew\" width=\"138\">\n",
        "<img src=\"https://blog.langchain.dev/content/images/size/w990/format/webp/2024/04/Tool-Calling-2.png\" width=\"185\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<div>\n",
        "  <h2>SUTRA by TWO Platforms </h2>\n",
        "  <p>SUTRA is a family of large multi-lingual language (LMLMs) models pioneered by Two Platforms. SUTRA’s dual-transformer approach extends the power of both MoE and Dense AI language model architectures, delivering cost-efficient multilingual capabilities for over 50+ languages. It powers scalable AI applications for conversation, search, and advanced reasoning, ensuring high-performance across diverse languages, domains and applications.</p>\n",
        "\n",
        "  <h2>LangChain's Tool Calling</h2>\n",
        "    <p>LangChain's tool calling enables language models to invoke external functions or APIs during conversations by defining tools with the @tool decorator and binding them to the model using .bind_tools(). This allows the model to generate structured outputs that match the tool's input schema, facilitating seamless integration of functionalities like calculations, translations, or data retrieval into AI applications.</p>\n",
        "  </div>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/18POcDv67qN0_CJo-_BPr6VE-r5RlXUYC?usp=sharing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw-nklWGXK5r"
      },
      "source": [
        "## Get Your API Keys\n",
        "\n",
        "Before you begin, make sure you have:\n",
        "\n",
        "1. A SUTRA API key (Get yours at [TWO AI's SUTRA API page](https://www.two.ai/sutra/api))\n",
        "2. Basic familiarity with Python and Jupyter notebooks\n",
        "\n",
        "This notebook is designed to run in Google Colab, so no local Python installation is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzPShy0qXNzv"
      },
      "source": [
        "##LangChain's Tool Calling With SUTRA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9fGd4cLXXDA"
      },
      "source": [
        "###1. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M0x_58FUx3G",
        "outputId": "129b6cc8-106b-497d-fbf9-18c4520e8587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m61.4/62.8 kB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q langchain langchain-core langchain-openai requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmAdKQAQc8Fm"
      },
      "source": [
        "### 2. Set Up Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lmvof_NodAu4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set the API key from Colab secrets\n",
        "os.environ[\"SUTRA_API_KEY\"] = userdata.get(\"SUTRA_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaOuhJW3dINP"
      },
      "source": [
        "###3. Initialize SUTRA LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paDupdWEdMkv"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "def get_sutra_llm(temperature=0.7):\n",
        "    \"\"\"Initialize Sutra LLM instance\"\"\"\n",
        "    return ChatOpenAI(\n",
        "        api_key=os.environ.get(\"SUTRA_API_KEY\"),\n",
        "        base_url=\"https://api.two.ai/v2\",\n",
        "        model=\"sutra-v2\",\n",
        "        temperature=temperature\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk_b84NrdPeL"
      },
      "source": [
        "###4. Basic Math Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtoL6gaJdSzK",
        "outputId": "04780d7f-ea53-4644-eb8d-a1cfb793461e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15\n",
            "25\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiplies two integers and returns the result.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "# Call the tool manually to see the output\n",
        "print(multiply.invoke({\"a\": 3, \"b\": 5}))\n",
        "\n",
        "\n",
        "@tool\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Adds two integers and returns the result.\"\"\"\n",
        "    return a + b\n",
        "\n",
        "# Test call\n",
        "print(add.invoke({\"a\": 10, \"b\": 15}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZJskjUndVzC"
      },
      "source": [
        "###5. Language Detection & Translation Tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X68JwNiEdY_n",
        "outputId": "0be225ef-91d2-4305-cc91-6a034eeff0e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'detected_language': 'Spanish', 'confidence': 0.9, 'text': 'Hola amigo'}\n",
            "नमस्ते\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def detect_language(text: str):\n",
        "    \"\"\"Detects the language of a given text based on predefined keywords.\"\"\"\n",
        "    languages = {\n",
        "        \"hello\": \"English\", \"hola\": \"Spanish\", \"namaste\": \"Hindi\",\n",
        "        \"bonjour\": \"French\", \"ni hao\": \"Chinese\", \"konichiwa\": \"Japanese\",\n",
        "        \"안녕하세요\": \"Korean\"\n",
        "    }\n",
        "    text_lower = text.lower()\n",
        "    detected = next((lang for key, lang in languages.items() if key in text_lower), \"English\")\n",
        "    return {\"detected_language\": detected, \"confidence\": 0.9, \"text\": text}\n",
        "\n",
        "# Test call\n",
        "print(detect_language.invoke({\"text\": \"Hola amigo\"}))\n",
        "\n",
        "@tool\n",
        "def translate_text(text: str, source_language: str, target_language: str):\n",
        "    \"\"\"Translates text from source language to target language using predefined mappings.\"\"\"\n",
        "    translations = {\n",
        "        (\"English\", \"Spanish\", \"hello\"): \"hola\",\n",
        "        (\"English\", \"Hindi\", \"hello\"): \"नमस्ते\",\n",
        "        (\"Hindi\", \"English\", \"namaste\"): \"hello\",\n",
        "    }\n",
        "    return translations.get((source_language, target_language, text.lower()), f\"[{target_language}] {text}\")\n",
        "\n",
        "# Test call\n",
        "print(translate_text.invoke({\n",
        "    \"text\": \"hello\",\n",
        "    \"source_language\": \"English\",\n",
        "    \"target_language\": \"Hindi\"\n",
        "}))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8MZLsLedcVf"
      },
      "source": [
        "###6. Currency Conversion Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8phxus9dfuf",
        "outputId": "69fada84-f886-4da7-d20e-925dafde289d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8350.0\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.tools import tool\n",
        "from langchain_core.tools import InjectedToolArg\n",
        "from typing import Annotated\n",
        "\n",
        "@tool\n",
        "def convert_currency(base_currency_value: float, conversion_rate: Annotated[float, InjectedToolArg]) -> float:\n",
        "    \"\"\"Converts a currency value using the given conversion rate.\"\"\"\n",
        "    return base_currency_value * conversion_rate\n",
        "\n",
        "# Example manual call\n",
        "print(convert_currency.invoke({\"base_currency_value\": 100, \"conversion_rate\": 83.5}))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX6_30-adl9O"
      },
      "source": [
        "###7. Weather Information (Mock)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0atMYcpdpRa",
        "outputId": "070cae1c-c2a8-408c-b75d-a37daa564879"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'temp': 32, 'condition': 'humid'}\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def get_weather(city: str, country_code: str):\n",
        "    \"\"\"Returns mock weather data for a given city and country code.\"\"\"\n",
        "    weather_data = {\n",
        "        \"new york:us\": {\"temp\": 22, \"condition\": \"sunny\"},\n",
        "        \"london:uk\": {\"temp\": 15, \"condition\": \"rainy\"},\n",
        "        \"mumbai:in\": {\"temp\": 32, \"condition\": \"humid\"}\n",
        "    }\n",
        "    key = f\"{city.lower()}:{country_code.lower()}\"\n",
        "    return weather_data.get(key, {\"temp\": 25, \"condition\": \"unknown\", \"humidity\": 50})\n",
        "\n",
        "# Test call\n",
        "print(get_weather.invoke({\"city\": \"Mumbai\", \"country_code\": \"IN\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqjMk6JWiZ09"
      },
      "source": [
        "### **8. Using bind_tools method**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Tgdh72xiGVv"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def add_numbers(a: int, b: int) -> int:\n",
        "    \"\"\"Add two integers and return the result.\"\"\"\n",
        "    return a + b\n",
        "\n",
        "@tool\n",
        "def detect_language(text: str) -> str:\n",
        "    \"\"\"Detects the language based on common greetings.\"\"\"\n",
        "    greetings = {\n",
        "        \"hello\": \"English\", \"hola\": \"Spanish\", \"namaste\": \"Hindi\",\n",
        "        \"bonjour\": \"French\", \"ni hao\": \"Chinese\", \"konichiwa\": \"Japanese\",\n",
        "        \"안녕하세요\": \"Korean\"\n",
        "    }\n",
        "    text_lower = text.lower()\n",
        "    for key, lang in greetings.items():\n",
        "        if key in text_lower:\n",
        "            return lang\n",
        "    return \"Unknown\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24aq4HZXkTzh"
      },
      "source": [
        "###Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niqvQ6_liMG3",
        "outputId": "3f935b6c-276a-4667-b1de-965324556a38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='45 plus 17 equals 62.' additional_kwargs={'refusal': None} response_metadata={'token_usage': None, 'model_name': 'sutra-v2', 'system_fingerprint': None, 'id': '6UmnAgLSqTNsTkCPPZxpQE', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--0799d28a-bf89-49a0-ac07-8d880acecc20-0'\n",
            "content=\"'Bonjour' is French for 'Hello'.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': None, 'model_name': 'sutra-v2', 'system_fingerprint': None, 'id': 'wqJrrR3ZdXaRWf2kaycRA6', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--9f050b52-349f-4d3a-972a-d89006123d38-0'\n"
          ]
        }
      ],
      "source": [
        "sutra_llm = get_sutra_llm()\n",
        "llm_with_tools = sutra_llm.bind_tools([add_numbers, detect_language])\n",
        "\n",
        "print(llm_with_tools.invoke(\"What is 45 plus 17?\"))\n",
        "print(llm_with_tools.invoke(\"Which language is this: 'Bonjour'?\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
