{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h3xx2SjnNX8"
      },
      "source": [
        "<div style=\"display: flex; align-items: center; gap: 40px;\">\n",
        "\n",
        "<img src=\"https://play-lh.googleusercontent.com/_O9p4Z4yucA2NLmZBu9mTJCuBwXeT9NcbtrDN6I8gKlkIPRySV0adOmbyipjSj9Gew\" width=\"130\">\n",
        "<img src=\"https://static.vecteezy.com/system/resources/previews/021/059/827/non_2x/chatgpt-logo-chat-gpt-icon-on-white-background-free-vector.jpg\" width=\"130\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<div>\n",
        "  <h2>SUTRA by TWO Platforms </h2>\n",
        "  <p>SUTRA is a family of large multi-lingual language (LMLMs) models pioneered by Two Platforms. SUTRA‚Äôs dual-transformer approach extends the power of both MoE and Dense AI language model architectures, delivering cost-efficient multilingual capabilities for over 50+ languages. It powers scalable AI applications for conversation, search, and advanced reasoning, ensuring high-performance across diverse languages, domains and applications.</p>\n",
        "\n",
        "  <h2>OpenAI Agents SDK</h2>\n",
        "    <p>The OpenAI Agents SDK enables you to build agentic AI apps in a lightweight, easy-to-use package with very few abstractions. It's a production-ready upgrade of our previous experimentation for agents, Swarm..</p>\n",
        "  </div>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1gLHm0yKqIIKIriNZ0zz2zI2t1duo8ocq?usp=sharing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXc5N3uTozoW"
      },
      "source": [
        "## Get Your API Keys\n",
        "\n",
        "Before you begin, make sure you have:\n",
        "\n",
        "1. A SUTRA API key (Get yours at [TWO AI's SUTRA API page](https://www.two.ai/sutra/api))\n",
        "2. Basic familiarity with Python and Jupyter notebooks\n",
        "\n",
        "This notebook is designed to run in Google Colab, so no local Python installation is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZyQ6qeEpJZ1"
      },
      "source": [
        "##**SUTRA Using OpenAI Agents SDK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_VOFtPrpWrn"
      },
      "source": [
        "###Install Required Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WkrLqOJ-N_u-"
      },
      "outputs": [],
      "source": [
        "!pip install \"openai-agents[litellm]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jTy2X_4peyH"
      },
      "source": [
        "###Setup API Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgzFSAh-OM63"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set the API key from Colab secrets\n",
        "os.environ[\"SUTRA_API_KEY\"] = userdata.get(\"SUTRA_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRfhYhfQqGAv"
      },
      "source": [
        "###Configuring Logging to Silence OpenAI Agent Warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B51rcCmoVe82"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.getLogger(\"openai.agents\").setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mp5c0YrqsjU"
      },
      "source": [
        "###Initializing and Executing a LiteLLM-Based Agent with SUTRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biPIsngSOd5r",
        "outputId": "6fe28960-9efa-46ef-bcd9-bcb197670a92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‡§á‡§ï‡•ç‡§µ‡§ø‡§ü‡•Ä ‡§ï‡§æ ‡§Æ‡§§‡§≤‡§¨ ‡§π‡•ã‡§§‡§æ ‡§π‡•à ‡§ï‡§ø‡§∏‡•Ä ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§Ø‡§æ ‡§∏‡§Ç‡§ó‡§†‡§® ‡§Æ‡•á‡§Ç ‡§Æ‡§æ‡§≤‡§ø‡§ï‡§æ‡§®‡§æ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞ ‡§Ø‡§æ ‡§π‡§ø‡§∏‡•ç‡§∏‡•á‡§¶‡§æ‡§∞‡•Ä‡•§ ‡§Ø‡§π ‡§è‡§ï ‡§µ‡§ø‡§§‡•ç‡§§‡•Ä‡§Ø ‡§∂‡§¨‡•ç‡§¶ ‡§π‡•à ‡§ú‡•ã ‡§Ü‡§Æ‡§§‡•å‡§∞ ‡§™‡§∞ ‡§∂‡•á‡§Ø‡§∞ ‡§¨‡§æ‡§ú‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§á‡§∏‡•ç‡§§‡•á‡§Æ‡§æ‡§≤ ‡§π‡•ã‡§§‡§æ ‡§π‡•à‡•§ ‡§ú‡§¨ ‡§Ü‡§™ ‡§ï‡§ø‡§∏‡•Ä ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§ï‡•á ‡§∂‡•á‡§Ø‡§∞ ‡§ñ‡§∞‡•Ä‡§¶‡§§‡•á ‡§π‡•à‡§Ç, ‡§§‡•ã ‡§Ü‡§™ ‡§â‡§∏ ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§π‡§ø‡§∏‡•ç‡§∏‡•á‡§¶‡§æ‡§∞ ‡§¨‡§® ‡§ú‡§æ‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§Ü‡§™‡§ï‡•ã ‡§â‡§∏‡§ï‡•á ‡§≤‡§æ‡§≠ ‡§î‡§∞ ‡§π‡§æ‡§®‡§ø ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§ï‡§æ ‡§π‡§ø‡§∏‡•ç‡§∏‡§æ ‡§Æ‡§ø‡§≤‡§§‡§æ ‡§π‡•à‡•§\n",
            "\n",
            "‡§á‡§ï‡•ç‡§µ‡§ø‡§ü‡•Ä ‡§ï‡•á ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§®‡§ø‡§Æ‡•ç‡§®‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§π‡•à‡§Ç:\n",
            "\n",
            "1. **‡§∏‡§æ‡§ß‡§æ‡§∞‡§£ ‡§∂‡•á‡§Ø‡§∞ (Common Stock)**: ‡§Ø‡•á ‡§∂‡•á‡§Ø‡§∞ ‡§Ü‡§Æ‡§§‡•å‡§∞ ‡§™‡§∞ ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§ï‡•á ‡§Æ‡§æ‡§≤‡§ø‡§ï‡§æ‡§®‡§æ ‡§π‡§ï ‡§ï‡•ã ‡§¶‡§∞‡•ç‡§∂‡§æ‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§∂‡•á‡§Ø‡§∞‡§ß‡§æ‡§∞‡§ï‡•ã‡§Ç ‡§ï‡•ã ‡§µ‡•ã‡§ü ‡§¶‡•á‡§®‡•á ‡§ï‡§æ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞ ‡§¶‡•á‡§§‡•á ‡§π‡•à‡§Ç‡•§ ‡§∏‡§æ‡§ß‡§æ‡§∞‡§£ ‡§∂‡•á‡§Ø‡§∞‡§ß‡§æ‡§∞‡§ï ‡§≤‡§æ‡§≠‡§æ‡§Ç‡§∂ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, ‡§≤‡•á‡§ï‡§ø‡§® ‡§â‡§®‡•ç‡§π‡•á‡§Ç ‡§™‡§π‡§≤‡•á ‡§¨‡§æ‡§Ç‡§°‡§ß‡§æ‡§∞‡§ï‡•ã‡§Ç ‡§î‡§∞ ‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï ‡§∂‡•á‡§Ø‡§∞‡§ß‡§æ‡§∞‡§ï‡•ã‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§\n",
            "\n",
            "2. **‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï ‡§∂‡•á‡§Ø‡§∞ (Preferred Stock)**: ‡§Ø‡•á ‡§∂‡•á‡§Ø‡§∞ ‡§∏‡§æ‡§ß‡§æ‡§∞‡§£ ‡§∂‡•á‡§Ø‡§∞ ‡§ï‡•Ä ‡§§‡•Å‡§≤‡§®‡§æ ‡§Æ‡•á‡§Ç ‡§ï‡•Å‡§õ ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç, ‡§ú‡•à‡§∏‡•á ‡§ï‡§ø ‡§∏‡•ç‡§•‡§ø‡§∞ ‡§≤‡§æ‡§≠‡§æ‡§Ç‡§∂ ‡§î‡§∞ ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§ï‡•á ‡§™‡§∞‡§ø‡§∏‡§Æ‡§æ‡§™‡§® ‡§ï‡•á ‡§∏‡§Æ‡§Ø ‡§™‡§π‡§≤‡•á ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§ï‡§æ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡•§\n",
            "\n",
            "‡§á‡§ï‡•ç‡§µ‡§ø‡§ü‡•Ä ‡§®‡§ø‡§µ‡•á‡§∂‡§ï‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§Ü‡§ï‡§∞‡•ç‡§∑‡§ï ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™ ‡§π‡•ã ‡§∏‡§ï‡§§‡§æ ‡§π‡•à ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Ø‡§π ‡§≤‡§Ç‡§¨‡•Ä ‡§Ö‡§µ‡§ß‡§ø ‡§Æ‡•á‡§Ç ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§∞‡§ø‡§ü‡§∞‡•ç‡§® ‡§¶‡•á ‡§∏‡§ï‡§§‡§æ ‡§π‡•à, ‡§≤‡•á‡§ï‡§ø‡§® ‡§á‡§∏‡§Æ‡•á‡§Ç ‡§ú‡•ã‡§ñ‡§ø‡§Æ ‡§≠‡•Ä ‡§π‡•ã‡§§‡§æ ‡§π‡•à, ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§∂‡•á‡§Ø‡§∞‡•ã‡§Ç ‡§ï‡•Ä ‡§ï‡•Ä‡§Æ‡§§‡•á‡§Ç ‡§ä‡§™‡§∞-‡§®‡•Ä‡§ö‡•á ‡§π‡•ã‡§§‡•Ä ‡§∞‡§π‡§§‡•Ä ‡§π‡•à‡§Ç‡•§\n"
          ]
        }
      ],
      "source": [
        "import nest_asyncio\n",
        "import asyncio\n",
        "import os\n",
        "from agents import Agent, Runner\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "\n",
        "# Patch the running event loop\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Main async logic\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Sutra Agent\",\n",
        "        instructions=\"You are a helpful assistant that responds in Hindi.\",\n",
        "        model=LitellmModel(\n",
        "            model=\"openai/sutra-v2\",\n",
        "            api_key=os.environ.get(\"SUTRA_API_KEY\"),\n",
        "            base_url=\"https://api.two.ai/v2\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(agent, \"‡§á‡§ï‡•ç‡§µ‡§ø‡§ü‡•Ä ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•ã‡§§‡§æ ‡§π‡•à?\")\n",
        "    print(result.final_output)\n",
        "\n",
        "# Run the async function safely\n",
        "await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzRQwLoLr5cB"
      },
      "source": [
        "###Streaming Response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFE9Nsfmr0Ld",
        "outputId": "ebe742a5-249b-45a0-aec0-d173c3955f2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üü¢ Streaming started...\n",
            "\n",
            "‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§Ö‡§§‡•ç‡§Ø‡§Ç‡§§ ‡§∏‡§Æ‡•É‡§¶‡•ç‡§ß ‡§î‡§∞ ‡§µ‡§ø‡§µ‡§ø‡§ß ‡§π‡•à, ‡§ú‡•ã ‡§π‡§ú‡§æ‡§∞‡•ã‡§Ç ‡§µ‡§∞‡•ç‡§∑‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§´‡•à‡§≤‡§æ ‡§π‡•Å‡§Ü ‡§π‡•à‡•§ ‡§á‡§∏‡•á ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§ï‡§æ‡§≤‡§ñ‡§Ç‡§°‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§≠‡§æ‡§ú‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à:\n",
            "\n",
            "1. **‡§™‡•ç‡§∞‡§æ‡§ö‡•Ä‡§® ‡§≠‡§æ‡§∞‡§§**: \n",
            "   - ‡§∏‡§ø‡§Ç‡§ß‡•Å ‡§ò‡§æ‡§ü‡•Ä ‡§∏‡§≠‡•ç‡§Ø‡§§‡§æ (‡§≤‡§ó‡§≠‡§ó 3300-1300 ‡§à‡§∏‡§æ ‡§™‡•Ç‡§∞‡•ç‡§µ): ‡§Ø‡§π ‡§∏‡§¨‡§∏‡•á ‡§™‡•Å‡§∞‡§æ‡§®‡•Ä ‡§ú‡•ç‡§û‡§æ‡§§ ‡§∏‡§≠‡•ç‡§Ø‡§§‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§è‡§ï ‡§•‡•Ä, ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§Æ‡•ã‡§π‡§®‡§ú‡•ã‡§¶‡§°‡§º‡•ã ‡§î‡§∞ ‡§π‡§°‡§º‡§™‡•ç‡§™‡§æ ‡§ú‡•à‡§∏‡•á ‡§®‡§ó‡§∞ ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§•‡•á‡•§\n",
            "   - ‡§µ‡•á‡§¶‡§ø‡§ï ‡§ï‡§æ‡§≤ (‡§≤‡§ó‡§≠‡§ó 1500-500 ‡§à‡§∏‡§æ ‡§™‡•Ç‡§∞‡•ç‡§µ): ‡§µ‡•à‡§¶‡§ø‡§ï ‡§∏‡§æ‡§π‡§ø‡§§‡•ç‡§Ø ‡§ï‡•Ä ‡§∞‡§ö‡§®‡§æ ‡§á‡§∏ ‡§¶‡•å‡§∞‡§æ‡§® ‡§π‡•Å‡§à, ‡§î‡§∞ ‡§Ü‡§∞‡•ç‡§Ø ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø ‡§ï‡§æ ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§π‡•Å‡§Ü‡•§\n",
            "\n",
            "2. **‡§ï‡•ç‡§≤‡§æ‡§∏‡§ø‡§ï‡§≤ ‡§≠‡§æ‡§∞‡§§**:\n",
            "   - ‡§Æ‡§π‡§æ‡§ú‡§®‡§™‡§¶ ‡§ï‡§æ‡§≤ (‡§≤‡§ó‡§≠‡§ó 600-300 ‡§à‡§∏‡§æ ‡§™‡•Ç‡§∞‡•ç‡§µ): ‡§á‡§∏ ‡§¶‡•å‡§∞‡§æ‡§® ‡§ï‡§à ‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§î‡§∞ ‡§ó‡§£‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§Ö‡§∏‡•ç‡§§‡§ø‡§§‡•ç‡§µ ‡§Æ‡•á‡§Ç ‡§Ü‡§è‡•§\n",
            "   - ‡§Æ‡•å‡§∞‡•ç‡§Ø ‡§∏‡§æ‡§Æ‡•ç‡§∞‡§æ‡§ú‡•ç‡§Ø (322-185 ‡§à‡§∏‡§æ ‡§™‡•Ç‡§∞‡•ç‡§µ): ‡§ö‡§Ç‡§¶‡•ç‡§∞‡§ó‡•Å‡§™‡•ç‡§§ ‡§Æ‡•å‡§∞‡•ç‡§Ø ‡§î‡§∞ ‡§Ö‡§∂‡•ã‡§ï ‡§Æ‡§π‡§æ‡§® ‡§ï‡•á ‡§§‡§π‡§§ ‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§è‡§ï ‡§¨‡§°‡§º‡§æ ‡§∏‡§æ‡§Æ‡•ç‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§¨‡§®‡§æ‡•§\n",
            "   - ‡§ó‡•Å‡§™‡•ç‡§§ ‡§∏‡§æ‡§Æ‡•ç‡§∞‡§æ‡§ú‡•ç‡§Ø (‡§≤‡§ó‡§≠‡§ó 320-550 ‡§à‡§∏‡•ç‡§µ‡•Ä): ‡§á‡§∏‡•á '‡§∏‡•ã‡§®‡•á ‡§ï‡•Ä ‡§Ö‡§µ‡§ß‡§ø' ‡§ï‡§π‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à, ‡§ú‡§¨ ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§®, ‡§ï‡§≤‡§æ ‡§î‡§∞ ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø ‡§Æ‡•á‡§Ç ‡§¨‡§°‡§º‡•Ä ‡§™‡•ç‡§∞‡§ó‡§§‡§ø ‡§π‡•Å‡§à‡•§\n",
            "\n",
            "3. **‡§Æ‡§ß‡•ç‡§Ø‡§ï‡§æ‡§≤‡•Ä‡§® ‡§≠‡§æ‡§∞‡§§**:\n",
            "   - ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§∏‡§≤‡•ç‡§§‡§®‡§§ (1206-1526): ‡§§‡•Å‡§∞‡•ç‡§ï‡•ã‡§Ç ‡§î‡§∞ ‡§Ö‡§´‡§ó‡§æ‡§®‡•ã‡§Ç ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§∏‡•ç‡§•‡§æ‡§™‡§ø‡§§ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§∞‡§æ‡§ú‡§µ‡§Ç‡§∂‡•ã‡§Ç ‡§ï‡§æ ‡§∂‡§æ‡§∏‡§®‡•§\n",
            "   - ‡§Æ‡•Å‡§ó‡§º‡§≤ ‡§∏‡§æ‡§Æ‡•ç‡§∞‡§æ‡§ú‡•ç‡§Ø (1526-1857): ‡§¨‡§æ‡§¨‡§∞ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§∏‡•ç‡§•‡§æ‡§™‡§ø‡§§, ‡§Ø‡§π ‡§∏‡§æ‡§Æ‡•ç‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§â‡§™‡§Æ‡§π‡§æ‡§¶‡•ç‡§µ‡•Ä‡§™ ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§∏‡§æ‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø‡§ï ‡§î‡§∞ ‡§∞‡§æ‡§ú‡§®‡•Ä‡§§‡§ø‡§ï ‡§Ø‡•Å‡§ó ‡§•‡§æ‡•§\n",
            "\n",
            "4. **‡§Ü‡§ß‡•Å‡§®‡§ø‡§ï ‡§≠‡§æ‡§∞‡§§**:\n",
            "   - ‡§¨‡•ç‡§∞‡§ø‡§ü‡§ø‡§∂ ‡§â‡§™‡§®‡§ø‡§µ‡•á‡§∂‡•Ä‡§Ø ‡§ï‡§æ‡§≤ (1858-1947): ‡§≠‡§æ‡§∞‡§§ ‡§™‡§∞ ‡§¨‡•ç‡§∞‡§ø‡§ü‡§ø‡§∂ ‡§∞‡§æ‡§ú ‡§ï‡§æ ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ ‡§î‡§∞ ‡§á‡§∏‡§ï‡•á ‡§ñ‡§ø‡§≤‡§æ‡§´ ‡§∏‡•ç‡§µ‡§§‡§Ç‡§§‡•ç‡§∞‡§§‡§æ ‡§∏‡§Ç‡§ó‡•ç‡§∞‡§æ‡§Æ‡•§\n",
            "   - ‡§∏‡•ç‡§µ‡§§‡§Ç‡§§‡•ç‡§∞‡§§‡§æ ‡§∏‡§Ç‡§ó‡•ç‡§∞‡§æ‡§Æ (1857-1947): ‡§Æ‡§π‡§æ‡§§‡•ç‡§Æ‡§æ ‡§ó‡§æ‡§Ç‡§ß‡•Ä, ‡§∏‡•Å‡§≠‡§æ‡§∑ ‡§ö‡§Ç‡§¶‡•ç‡§∞ ‡§¨‡•ã‡§∏, ‡§î‡§∞ ‡§Ö‡§®‡•ç‡§Ø ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§®‡•á‡§§‡•É‡§§‡•ç‡§µ ‡§Æ‡•á‡§Ç ‡§¶‡•á‡§∂ ‡§®‡•á ‡§∏‡•ç‡§µ‡§§‡§Ç‡§§‡•ç‡§∞‡§§‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§Ç‡§ò‡§∞‡•ç‡§∑ ‡§ï‡§ø‡§Ø‡§æ‡•§\n",
            "   - ‡§∏‡•ç‡§µ‡§§‡§Ç‡§§‡•ç‡§∞‡§§‡§æ (15 ‡§Ö‡§ó‡§∏‡•ç‡§§ 1947): ‡§≠‡§æ‡§∞‡§§ ‡§®‡•á ‡§∏‡•ç‡§µ‡§§‡§Ç‡§§‡•ç‡§∞‡§§‡§æ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡•Ä ‡§î‡§∞ ‡§è‡§ï ‡§≤‡•ã‡§ï‡§§‡§æ‡§Ç‡§§‡•ç‡§∞‡§ø‡§ï ‡§ó‡§£‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§¨‡§®‡§æ‡•§\n",
            "\n",
            "5. **‡§∏‡§Æ‡§ï‡§æ‡§≤‡•Ä‡§® ‡§≠‡§æ‡§∞‡§§**:\n",
            "   - ‡§≠‡§æ‡§∞‡§§ ‡§Ü‡§ú ‡§è‡§ï ‡§≤‡•ã‡§ï‡§§‡§æ‡§Ç‡§§‡•ç‡§∞‡§ø‡§ï ‡§ó‡§£‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§π‡•à, ‡§ú‡•ã ‡§Ü‡§∞‡•ç‡§•‡§ø‡§ï ‡§µ‡§ø‡§ï‡§æ‡§∏, ‡§∏‡§æ‡§Æ‡§æ‡§ú‡§ø‡§ï ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§î‡§∞ ‡§µ‡•à‡§∂‡•ç‡§µ‡§ø‡§ï ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø ‡§≠‡§æ‡§ó‡•Ä‡§¶‡§æ‡§∞‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ú‡§æ‡§®‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§\n",
            "\n",
            "‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø‡§Ø‡•ã‡§Ç, ‡§ß‡§∞‡•ç‡§Æ‡•ã‡§Ç ‡§î‡§∞ ‡§≠‡§æ‡§∑‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§∏‡§Ç‡§ó‡§Æ ‡§π‡•à, ‡§ú‡§ø‡§∏‡§®‡•á ‡§á‡§∏‡•á ‡§è‡§ï ‡§Ö‡§¶‡•ç‡§µ‡§ø‡§§‡•Ä‡§Ø ‡§î‡§∞ ‡§µ‡§ø‡§µ‡§ø‡§ß ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞ ‡§¨‡§®‡§æ‡§Ø‡§æ ‡§π‡•à‡•§\n",
            "‚úÖ Streaming complete.\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "import os\n",
        "from openai.types.responses import ResponseTextDeltaEvent\n",
        "from agents import Agent, Runner\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "\n",
        "async def main():\n",
        "    # Create an Agent using Sutra (via LiteLLM)\n",
        "    agent = Agent(\n",
        "        name=\"Sutra Stream Agent\",\n",
        "        instructions=\"‡§§‡•Å‡§Æ ‡§è‡§ï ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•ã ‡§ú‡•ã ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§§‡§æ ‡§π‡•à‡•§\",  # Instructions in Hindi\n",
        "        model=LitellmModel(\n",
        "            model=\"openai/sutra-v2\",\n",
        "            api_key=os.environ.get(\"SUTRA_API_KEY\"),\n",
        "            base_url=\"https://api.two.ai/v2\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    # Start streaming the response\n",
        "    result = Runner.run_streamed(agent, input=\"‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§¨‡§§‡§æ‡§á‡§è‡•§\")\n",
        "\n",
        "    print(\"üü¢ Streaming started...\\n\")\n",
        "    async for event in result.stream_events():\n",
        "        # Print LLM tokens as they're streamed\n",
        "        if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
        "            print(event.data.delta, end=\"\", flush=True)\n",
        "\n",
        "    print(\"\\n‚úÖ Streaming complete.\")\n",
        "\n",
        "# üîÅ Run in a proper async environment\n",
        "await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvsGvNEiq4Bm"
      },
      "source": [
        "###Define Weather Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pgPrGSGReln"
      },
      "outputs": [],
      "source": [
        "from agents import function_tool\n",
        "\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Get weather details for a given city.\"\"\"\n",
        "    return f\"{city} ‡§Æ‡•á‡§Ç ‡§Æ‡•å‡§∏‡§Æ ‡§¨‡§π‡•Å‡§§ ‡§π‡•Ä ‡§∏‡•Å‡§π‡§æ‡§µ‡§®‡§æ ‡§π‡•à‡•§\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdjXRcaCrGU5"
      },
      "source": [
        "###Define User Info Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dIzmq3pRgjM"
      },
      "outputs": [],
      "source": [
        "from typing import Any\n",
        "from pydantic import BaseModel\n",
        "from agents import FunctionTool, RunContextWrapper\n",
        "\n",
        "class UserInfo(BaseModel):\n",
        "    name: str\n",
        "    age: int\n",
        "\n",
        "async def process_user(ctx: RunContextWrapper[Any], args: str) -> str:\n",
        "    data = UserInfo.model_validate_json(args)\n",
        "    return f\"{data.name} ‡§ï‡•Ä ‡§â‡§Æ‡•ç‡§∞ {data.age} ‡§µ‡§∞‡•ç‡§∑ ‡§π‡•à‡•§\"\n",
        "\n",
        "process_user_tool = FunctionTool(\n",
        "    name=\"process_user_info\",\n",
        "    description=\"‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡•ã ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§ø‡§§ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§\",\n",
        "    params_json_schema=UserInfo.model_json_schema(),\n",
        "    on_invoke_tool=process_user\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOfqmk4ArTgK"
      },
      "source": [
        "###Translation Agent Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFbgkw2dRilV"
      },
      "outputs": [],
      "source": [
        "from agents import Agent\n",
        "\n",
        "hindi_translator = Agent(\n",
        "    name=\"Hindi Translator\",\n",
        "    instructions=\"‡§Ü‡§™ ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§ï‡•á ‡§∏‡§Ç‡§¶‡•á‡§∂ ‡§ï‡•ã ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§\",\n",
        ")\n",
        "\n",
        "# Turn agent into a tool\n",
        "translator_tool = hindi_translator.as_tool(\n",
        "    tool_name=\"translate_to_hindi\",\n",
        "    tool_description=\"‡§∏‡§Ç‡§¶‡•á‡§∂ ‡§ï‡•ã ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ï‡§∞‡•á‡§Ç‡•§\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvtBdKvnrhQN"
      },
      "source": [
        "###Run Multi-Tool Sutra Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u3bDupMRk7e",
        "outputId": "20d5137b-85c2-4f1e-f638-9162b210e110"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‡§ú‡§Ø‡§™‡•Å‡§∞ ‡§ï‡§æ ‡§Æ‡•å‡§∏‡§Æ ‡§Ü‡§Æ‡§§‡•å‡§∞ ‡§™‡§∞ ‡§ó‡§∞‡•ç‡§Æ ‡§î‡§∞ ‡§∂‡•Å‡§∑‡•ç‡§ï ‡§π‡•ã‡§§‡§æ ‡§π‡•à, ‡§µ‡§ø‡§∂‡•á‡§∑‡§ï‡§∞ ‡§ó‡§∞‡•ç‡§Æ‡§ø‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç (‡§Æ‡§æ‡§∞‡•ç‡§ö ‡§∏‡•á ‡§ú‡•Ç‡§®) ‡§ú‡§¨ ‡§§‡§æ‡§™‡§Æ‡§æ‡§® 40 ‡§°‡§ø‡§ó‡•ç‡§∞‡•Ä ‡§∏‡•á‡§≤‡•ç‡§∏‡§ø‡§Ø‡§∏ ‡§§‡§ï ‡§™‡§π‡•Å‡§Å‡§ö ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§ ‡§Æ‡§æ‡§®‡§∏‡•Ç‡§® (‡§ú‡•Å‡§≤‡§æ‡§à ‡§∏‡•á ‡§∏‡§ø‡§§‡§Ç‡§¨‡§∞) ‡§ï‡•á ‡§¶‡•å‡§∞‡§æ‡§®, ‡§∂‡§π‡§∞ ‡§Æ‡•á‡§Ç ‡§¨‡§æ‡§∞‡§ø‡§∂ ‡§π‡•ã‡§§‡•Ä ‡§π‡•à, ‡§ú‡§ø‡§∏‡§∏‡•á ‡§Æ‡•å‡§∏‡§Æ ‡§•‡•ã‡§°‡§º‡•Ä ‡§∞‡§æ‡§π‡§§ ‡§Æ‡§ø‡§≤‡§§‡•Ä ‡§π‡•à‡•§ ‡§∏‡§∞‡•ç‡§¶‡§ø‡§Ø‡•ã‡§Ç (‡§¶‡§ø‡§∏‡§Ç‡§¨‡§∞ ‡§∏‡•á ‡§´‡§∞‡§µ‡§∞‡•Ä) ‡§Æ‡•á‡§Ç, ‡§§‡§æ‡§™‡§Æ‡§æ‡§® 5-10 ‡§°‡§ø‡§ó‡•ç‡§∞‡•Ä ‡§∏‡•á‡§≤‡•ç‡§∏‡§ø‡§Ø‡§∏ ‡§§‡§ï ‡§ó‡§ø‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§†‡§Ç‡§°‡§æ ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞‡§æ‡§§‡§æ ‡§π‡•à‡•§ \n",
            "\n",
            "‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§® ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ú‡§æ‡§®‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§™ ‡§Æ‡•å‡§∏‡§Æ ‡§∏‡•á‡§µ‡§æ ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü ‡§Ø‡§æ ‡§ê‡§™‡•ç‡§∏ ‡§™‡§∞ ‡§¶‡•á‡§ñ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§\n"
          ]
        }
      ],
      "source": [
        "import nest_asyncio\n",
        "import asyncio\n",
        "import os\n",
        "from agents import Agent, Runner\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Sutra Agent\",\n",
        "        instructions=\"‡§Ü‡§™ ‡§è‡§ï ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•à‡§Ç ‡§ú‡•ã ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§§‡§æ ‡§π‡•à‡•§\",\n",
        "        model=LitellmModel(\n",
        "            model=\"openai/sutra-v2\",\n",
        "            api_key=os.environ[\"SUTRA_API_KEY\"],\n",
        "            base_url=\"https://api.two.ai/v2\"\n",
        "        ),\n",
        "        tools=[get_weather, process_user_tool, translator_tool],\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(agent, \"‡§Æ‡•Å‡§ù‡•á ‡§ú‡§Ø‡§™‡•Å‡§∞ ‡§ï‡•á ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§¨‡§§‡§æ‡§á‡§è‡•§\")\n",
        "    print(result.final_output)\n",
        "\n",
        "await main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsKJWvMhsm9I"
      },
      "source": [
        "###Guardrails via OpenAI Agents SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-X1XzOcvUsB-"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "import asyncio\n",
        "import os\n",
        "from pydantic import BaseModel\n",
        "from agents import (\n",
        "    Agent,\n",
        "    Runner,\n",
        "    function_tool,\n",
        "    GuardrailFunctionOutput,\n",
        "    RunContextWrapper,\n",
        "    InputGuardrailTripwireTriggered,\n",
        "    input_guardrail,\n",
        "    TResponseInputItem,\n",
        ")\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "\n",
        "# Patch event loop for Jupyter or other async environments\n",
        "nest_asyncio.apply()\n",
        "\n",
        "\n",
        "# Define the guardrail output model\n",
        "class MathHomeworkOutput(BaseModel):\n",
        "    is_math_homework: bool\n",
        "    reasoning: str\n",
        "\n",
        "# Setup guardrail agent - MUST output strict JSON only!\n",
        "guardrail_agent = Agent(\n",
        "    name=\"Math Homework Guardrail\",\n",
        "    instructions=(\n",
        "        \"You are a JSON API. Determine if the input asks for math homework help.\\n\"\n",
        "        \"Output ONLY a JSON object with fields:\\n\"\n",
        "        \"- is_math_homework (boolean)\\n\"\n",
        "        \"- reasoning (string)\\n\"\n",
        "        \"Do NOT output any extra text.\"\n",
        "    ),\n",
        "    output_type=MathHomeworkOutput,\n",
        "    model=LitellmModel(\n",
        "        model=\"openai/sutra-v2\",\n",
        "        api_key=os.environ.get(\"SUTRA_API_KEY\"),\n",
        "        base_url=\"https://api.two.ai/v2\",\n",
        "\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Guardrail function using input_guardrail decorator\n",
        "@input_guardrail\n",
        "async def math_guardrail(\n",
        "    ctx: RunContextWrapper[None],\n",
        "    agent: Agent,\n",
        "    input: str | list[TResponseInputItem]\n",
        ") -> GuardrailFunctionOutput:\n",
        "    result = await Runner.run(guardrail_agent, input, context=ctx.context)\n",
        "    return GuardrailFunctionOutput(\n",
        "        output_info=result.final_output,\n",
        "        tripwire_triggered=result.final_output.is_math_homework,\n",
        "    )\n",
        "\n",
        "# Main agent setup with Sutra model and input guardrail\n",
        "main_agent = Agent(\n",
        "    name=\"Sutra Agent\",\n",
        "    instructions=\"You are a helpful assistant that responds in Hindi.\",\n",
        "    model=LitellmModel(\n",
        "        model=\"openai/sutra-v2\",\n",
        "        api_key=os.environ.get(\"SUTRA_API_KEY\"),\n",
        "        base_url=\"https://api.two.ai/v2\",\n",
        "    ),\n",
        "    tools=[get_weather],\n",
        "    input_guardrails=[math_guardrail],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU_xkcDjs4Hr"
      },
      "source": [
        "### Guardrail Blocking vs Allowing Queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3fVPQyiVRCV",
        "outputId": "01f910d3-d4ab-4947-8185-3b0792b3d9cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1 - ‚ö†Ô∏è Guardrail triggered: Math homework detected! Agent run stopped.\n",
            "Example 2 - Agent response: ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§ï‡§æ ‡§Æ‡•å‡§∏‡§Æ ‡§Ü‡§Æ‡§§‡•å‡§∞ ‡§™‡§∞ ‡§ö‡§æ‡§∞ ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§Æ‡•å‡§∏‡§Æ‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§¨‡§Ç‡§ü‡§æ ‡§π‡•ã‡§§‡§æ ‡§π‡•à: ‡§ó‡§∞‡•ç‡§Æ‡•Ä, ‡§Æ‡§æ‡§®‡§∏‡•Ç‡§®, ‡§∏‡§∞‡•ç‡§¶‡•Ä ‡§î‡§∞ ‡§™‡§§‡§ù‡§°‡§º‡•§\n",
            "\n",
            "1. **‡§ó‡§∞‡•ç‡§Æ‡•Ä (‡§Æ‡§æ‡§∞‡•ç‡§ö ‡§∏‡•á ‡§ú‡•Ç‡§®)**: ‡§Æ‡§æ‡§∞‡•ç‡§ö ‡§∏‡•á ‡§ú‡•Ç‡§® ‡§§‡§ï ‡§ï‡§æ ‡§∏‡§Æ‡§Ø ‡§ó‡§∞‡•ç‡§Æ‡•Ä ‡§ï‡§æ ‡§π‡•ã‡§§‡§æ ‡§π‡•à‡•§ ‡§á‡§∏ ‡§¶‡•å‡§∞‡§æ‡§® ‡§§‡§æ‡§™‡§Æ‡§æ‡§® 30¬∞C ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ 45¬∞C ‡§§‡§ï ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§ ‡§Æ‡§à ‡§î‡§∞ ‡§ú‡•Ç‡§® ‡§Æ‡•á‡§Ç ‡§ó‡§∞‡•ç‡§Æ‡•Ä ‡§∏‡§¨‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§π‡•ã‡§§‡•Ä ‡§π‡•à‡•§\n",
            "\n",
            "2. **‡§Æ‡§æ‡§®‡§∏‡•Ç‡§® (‡§ú‡•Å‡§≤‡§æ‡§à ‡§∏‡•á ‡§∏‡§ø‡§§‡§Ç‡§¨‡§∞)**: ‡§ú‡•Å‡§≤‡§æ‡§à ‡§Æ‡•á‡§Ç ‡§Æ‡§æ‡§®‡§∏‡•Ç‡§® ‡§ï‡•Ä ‡§∂‡•Å‡§∞‡•Å‡§Ü‡§§ ‡§π‡•ã‡§§‡•Ä ‡§π‡•à, ‡§î‡§∞ ‡§Ø‡§π ‡§∏‡§ø‡§§‡§Ç‡§¨‡§∞ ‡§§‡§ï ‡§ú‡§æ‡§∞‡•Ä ‡§∞‡§π‡§§‡§æ ‡§π‡•à‡•§ ‡§á‡§∏ ‡§¶‡•å‡§∞‡§æ‡§® ‡§¨‡§æ‡§∞‡§ø‡§∂ ‡§π‡•ã‡§§‡•Ä ‡§π‡•à, ‡§ú‡•ã ‡§§‡§æ‡§™‡§Æ‡§æ‡§® ‡§ï‡•ã ‡§•‡•ã‡§°‡§º‡§æ ‡§ï‡§Æ ‡§ï‡§∞ ‡§¶‡•á‡§§‡•Ä ‡§π‡•à‡•§ ‡§î‡§∏‡§§ ‡§µ‡§∞‡•ç‡§∑‡§æ ‡§≤‡§ó‡§≠‡§ó 600 ‡§Æ‡§ø‡§Æ‡•Ä ‡§π‡•ã‡§§‡•Ä ‡§π‡•à‡•§\n",
            "\n",
            "3. **‡§∏‡§∞‡•ç‡§¶‡•Ä (‡§¶‡§ø‡§∏‡§Ç‡§¨‡§∞ ‡§∏‡•á ‡§´‡§∞‡§µ‡§∞‡•Ä)**: ‡§¶‡§ø‡§∏‡§Ç‡§¨‡§∞ ‡§∏‡•á ‡§´‡§∞‡§µ‡§∞‡•Ä ‡§§‡§ï ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§Æ‡•á‡§Ç ‡§∏‡§∞‡•ç‡§¶‡•Ä ‡§ï‡§æ ‡§Æ‡•å‡§∏‡§Æ ‡§π‡•ã‡§§‡§æ ‡§π‡•à‡•§ ‡§§‡§æ‡§™‡§Æ‡§æ‡§® 5¬∞C ‡§∏‡•á 20¬∞C ‡§ï‡•á ‡§¨‡•Ä‡§ö ‡§∞‡§π‡§§‡§æ ‡§π‡•à‡•§ ‡§ú‡§®‡§µ‡§∞‡•Ä ‡§∏‡§¨‡§∏‡•á ‡§†‡§Ç‡§°‡§æ ‡§Æ‡§π‡•Ä‡§®‡§æ ‡§π‡•ã‡§§‡§æ ‡§π‡•à‡•§\n",
            "\n",
            "4. **‡§™‡§§‡§ù‡§°‡§º (‡§Ö‡§ï‡•ç‡§ü‡•Ç‡§¨‡§∞ ‡§∏‡•á ‡§®‡§µ‡§Ç‡§¨‡§∞)**: ‡§Ö‡§ï‡•ç‡§ü‡•Ç‡§¨‡§∞ ‡§î‡§∞ ‡§®‡§µ‡§Ç‡§¨‡§∞ ‡§Æ‡•á‡§Ç ‡§Æ‡•å‡§∏‡§Æ ‡§∏‡•Å‡§π‡§æ‡§µ‡§®‡§æ ‡§∞‡§π‡§§‡§æ ‡§π‡•à‡•§ ‡§§‡§æ‡§™‡§Æ‡§æ‡§® ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø‡§§‡§É 15¬∞C ‡§∏‡•á 30¬∞C ‡§ï‡•á ‡§¨‡•Ä‡§ö ‡§π‡•ã‡§§‡§æ ‡§π‡•à‡•§\n",
            "\n",
            "‡§Ü‡§™ ‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§® ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•Ä ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü ‡§Ø‡§æ ‡§ê‡§™‡•ç‡§∏ ‡§¶‡•á‡§ñ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Ø‡§π ‡§∏‡§Æ‡§Ø ‡§ï‡•á ‡§∏‡§æ‡§• ‡§¨‡§¶‡§≤‡§§‡§æ ‡§∞‡§π‡§§‡§æ ‡§π‡•à‡•§\n"
          ]
        }
      ],
      "source": [
        "async def main():\n",
        "    # Example 1: Math homework input (should trigger guardrail)\n",
        "    try:\n",
        "        response = await Runner.run(main_agent, \"‡§Æ‡•Å‡§ù‡•á 2x + 3 = 11 ‡§ï‡§æ ‡§π‡§≤ ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡•á‡§Ç‡•§\")\n",
        "        print(\"Example 1 - Agent response:\", response.final_output)\n",
        "    except InputGuardrailTripwireTriggered:\n",
        "        print(\"Example 1 - ‚ö†Ô∏è Guardrail triggered: Math homework detected! Agent run stopped.\")\n",
        "\n",
        "    # Example 2: Non-math input (should NOT trigger guardrail)\n",
        "    try:\n",
        "        response = await Runner.run(main_agent, \"‡§Æ‡•Å‡§ù‡•á ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§ï‡•á ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§¨‡§§‡§æ‡§ì‡•§\")\n",
        "        print(\"Example 2 - Agent response:\", response.final_output)\n",
        "    except InputGuardrailTripwireTriggered:\n",
        "        print(\"Example 2 - ‚ö†Ô∏è Guardrail triggered unexpectedly!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R-635wmtbDO"
      },
      "source": [
        "###Orchestrating multiple agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wO-ywLpVX0sR",
        "outputId": "b2c3049b-72f0-41a7-fbb9-cf3437641684"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Orchestration via code =====\n",
            "\n",
            "[Research Agent Output]: Climate change significantly impacts agriculture through alterations in temperature, precipitation patterns, and the frequency of extreme weather events. Key effects include:\n",
            "\n",
            "1. **Crop Yields**: Changes in temperature can affect crop growth cycles, potentially reducing yields for heat-sensitive crops like wheat and maize, especially in tropical regions.\n",
            "\n",
            "2. **Water Availability**: Altered precipitation patterns may lead to droughts in some areas and flooding in others, affecting irrigation and water supply for farming.\n",
            "\n",
            "3. **Pest and Disease Pressure**: Warmer temperatures can expand the range and lifecycle of pests and diseases, posing new challenges for crop management.\n",
            "\n",
            "4. **Soil Health**: Increased rainfall intensity can lead to soil erosion and degradation, while rising temperatures can affect soil moisture content and nutrient availability.\n",
            "\n",
            "5. **Food Security**: Lower agricultural productivity can threaten food security, particularly in developing countries that rely heavily on rain-fed agriculture.\n",
            "\n",
            "6. **Adaptation Strategies**: Farmers may need to adopt new practices, such as drought-resistant crop varieties, improved water management techniques, and diversified cropping systems to mitigate these impacts.\n",
            "\n",
            "Overall, addressing climate change's impact on agriculture is crucial for ensuring sustainable food production and security in the future.\n",
            "\n",
            "[Writer Agent Output]: ### The Impact of Climate Change on Agriculture: Challenges and Adaptation Strategies\n",
            "\n",
            "Climate change poses a significant threat to global agriculture, influencing various aspects of farming practices and food security. As temperatures rise, precipitation patterns shift, and extreme weather events become more frequent, the agricultural sector faces unprecedented challenges. Understanding these impacts is essential for developing effective adaptation strategies that ensure sustainable food production.\n",
            "\n",
            "#### 1. Crop Yields\n",
            "\n",
            "One of the most immediate effects of climate change on agriculture is the alteration of crop yields. Temperature changes can disrupt growth cycles, particularly affecting heat-sensitive crops such as wheat and maize. In tropical regions, where temperatures are already high, even slight increases can lead to substantial reductions in crop productivity. For instance, studies indicate that a 1¬∞C rise in temperature could result in a 10% decrease in yields for staple crops, threatening the livelihoods of millions who depend on these crops for survival.\n",
            "\n",
            "#### 2. Water Availability\n",
            "\n",
            "Water availability is another critical concern as climate change alters precipitation patterns. Some regions may experience prolonged droughts, while others may face increased flooding. This variability complicates irrigation practices and can strain water supplies necessary for farming. Areas that rely heavily on rain-fed agriculture are particularly vulnerable, as unpredictable rainfall can lead to crop failures and reduced harvests.\n",
            "\n",
            "#### 3. Pest and Disease Pressure\n",
            "\n",
            "Warmer temperatures also create favorable conditions for pests and diseases, expanding their range and lifecycle. This shift poses new challenges for farmers, as they must adapt their pest management strategies to combat an increasing number of threats. For example, insects like locusts and aphids thrive in warmer climates, potentially leading to devastating infestations that can wipe out crops.\n",
            "\n",
            "#### 4. Soil Health\n",
            "\n",
            "The health of soil is crucial for sustainable agriculture, yet climate change threatens its integrity. Increased rainfall intensity can cause soil erosion and degradation, stripping away vital nutrients needed for crop growth. Additionally, rising temperatures can affect soil moisture content, leading to nutrient leaching and reduced fertility. Healthy soil is foundational to productive agriculture, and its degradation can have long-lasting impacts on food production systems.\n",
            "\n",
            "#### 5. Food Security\n",
            "\n",
            "The cumulative effects of reduced agricultural productivity due to climate change pose a significant threat to food security, especially in developing countries. These nations often rely on rain-fed agriculture and lack the resources to implement adaptive measures. As crop yields decline, food prices may rise, exacerbating hunger and malnutrition among vulnerable populations. Ensuring food security in the face of climate change is imperative for global stability and health.\n",
            "\n",
            "#### 6. Adaptation Strategies\n",
            "\n",
            "To mitigate the impacts of climate change on agriculture, farmers and policymakers must adopt innovative adaptation strategies. These may include:\n",
            "\n",
            "- **Drought-resistant Crop Varieties**: Developing and planting crops that can withstand prolonged periods of low water availability is crucial for maintaining yields in drier conditions.\n",
            "  \n",
            "- **Improved Water Management Techniques**: Implementing efficient irrigation systems and rainwater harvesting can help ensure a reliable water supply for crops, even in changing climates.\n",
            "  \n",
            "- **Diversified Cropping Systems**: Rotating crops and integrating various species can enhance resilience against pests and diseases, while also improving soil health.\n",
            "\n",
            "By embracing these strategies, the agricultural sector can better navigate the challenges posed by climate change and work towards sustainable food production.\n",
            "\n",
            "### Conclusion\n",
            "\n",
            "Addressing the impacts of climate change on agriculture is not just a matter of improving farming practices; it is essential for ensuring food security and sustainability in the future. By understanding the challenges and implementing effective adaptation strategies, we can build a resilient agricultural system capable of withstanding the pressures of a changing climate.\n",
            "\n",
            "===== Orchestration via LLM handoffs =====\n",
            "\n",
            "[Orchestrator Agent Output]: **Blog Post Workflow on \"Climate Change Impact on Agriculture\"**\n",
            "\n",
            "1. **Research Tasks Delegation to Research Agent:**\n",
            "   - Investigate the current scientific consensus on climate change and its effects on agricultural productivity.\n",
            "   - Collect data on specific crops most affected by climate change, including changes in yield, growth patterns, and geographic distribution.\n",
            "   - Explore case studies from different regions (e.g., North America, Sub-Saharan Africa, Southeast Asia) that illustrate the impact of climate change on agriculture.\n",
            "   - Analyze potential adaptive strategies that farmers can implement to mitigate the effects of climate change.\n",
            "   - Gather statistics on economic impacts, such as changes in food prices, farmer income, and food security related to climate change.\n",
            "   - Review policy responses from governments and organizations addressing climate change in agriculture.\n",
            "\n",
            "2. **Writing Delegation to Writer Agent:**\n",
            "   - Use the research output to craft a comprehensive blog post that includes:\n",
            "     - An introduction outlining the urgency of addressing climate change in the context of agriculture.\n",
            "     - A section detailing the scientific findings on how climate change affects crop yields, with specific examples.\n",
            "     - Case studies showcasing real-world impacts on farmers and communities.\n",
            "     - Discussion of adaptive strategies and innovations in agricultural practices to combat climate change.\n",
            "     - An analysis of the economic implications of climate change on agriculture, supported by statistics.\n",
            "     - Conclusion summarizing the importance of proactive measures and policy interventions to support sustainable agriculture in the face of climate change.\n",
            "\n",
            "Once the research tasks are completed, the Writer Agent will compile the information into a structured and engaging blog post.\n"
          ]
        }
      ],
      "source": [
        "import nest_asyncio\n",
        "import asyncio\n",
        "import os\n",
        "from agents import Agent, Runner, function_tool\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Function tool example (optional)\n",
        "@function_tool\n",
        "def search_web(query: str) -> str:\n",
        "    # Placeholder: pretend to search web and return snippet\n",
        "    return f\"Search results for '{query}': Important info about {query}.\"\n",
        "\n",
        "# Setup Research Agent\n",
        "research_agent = Agent(\n",
        "    name=\"Research Agent\",\n",
        "    instructions=\"You research topics and return concise summaries.\",\n",
        "    model=LitellmModel(\n",
        "        model=\"openai/sutra-v2\",\n",
        "        api_key=os.environ.get(\"SUTRA_API_KEY\"),\n",
        "        base_url=\"https://api.two.ai/v2\",\n",
        "    ),\n",
        "    tools=[search_web],\n",
        ")\n",
        "\n",
        "# Setup Writer Agent\n",
        "writer_agent = Agent(\n",
        "    name=\"Writer Agent\",\n",
        "    instructions=\"You write a blog post based on the provided research notes.\",\n",
        "    model=LitellmModel(\n",
        "        model=\"openai/sutra-v2\",\n",
        "        api_key=os.environ.get(\"SUTRA_API_KEY\"),\n",
        "        base_url=\"https://api.two.ai/v2\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Orchestrator Agent: will delegate via handoffs\n",
        "orchestrator_agent = Agent(\n",
        "    name=\"Orchestrator Agent\",\n",
        "    instructions=(\n",
        "        \"You plan a blog post workflow. \"\n",
        "        \"First, delegate research tasks to the Research Agent, \"\n",
        "        \"then delegate writing to the Writer Agent using research output.\"\n",
        "    ),\n",
        "    model=LitellmModel(\n",
        "        model=\"openai/sutra-v2\",\n",
        "        api_key=os.environ.get(\"SUTRA_API_KEY\"),\n",
        "        base_url=\"https://api.two.ai/v2\",\n",
        "    ),\n",
        "    handoffs=[research_agent, writer_agent],  # allows delegating tasks\n",
        ")\n",
        "\n",
        "# -------- ORCHESTRATION VIA CODE --------\n",
        "async def orchestrate_via_code(topic: str):\n",
        "    # Step 1: Run Research Agent\n",
        "    research_result = await Runner.run(research_agent, topic)\n",
        "    research_notes = research_result.final_output\n",
        "    print(\"\\n[Research Agent Output]:\", research_notes)\n",
        "\n",
        "    # Step 2: Run Writer Agent with research notes as input\n",
        "    writer_result = await Runner.run(writer_agent, research_notes)\n",
        "    blog_post = writer_result.final_output\n",
        "    print(\"\\n[Writer Agent Output]:\", blog_post)\n",
        "\n",
        "# -------- ORCHESTRATION VIA LLM HANDOFFS --------\n",
        "async def orchestrate_via_llm(topic: str):\n",
        "    # Just call orchestrator agent with the topic and it handles handoffs internally\n",
        "    result = await Runner.run(orchestrator_agent, topic)\n",
        "    print(\"\\n[Orchestrator Agent Output]:\", result.final_output)\n",
        "\n",
        "async def main():\n",
        "    topic = \"Climate change impact on agriculture\"\n",
        "\n",
        "    print(\"===== Orchestration via code =====\")\n",
        "    await orchestrate_via_code(topic)\n",
        "\n",
        "    print(\"\\n===== Orchestration via LLM handoffs =====\")\n",
        "    await orchestrate_via_llm(topic)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
