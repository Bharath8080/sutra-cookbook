{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt64J23APu_K"
      },
      "source": [
        "# Basics of SUTRA Streaming with OpenAI Client\n",
        "\n",
        "\n",
        "<img src=\"https://play-lh.googleusercontent.com/_O9p4Z4yucA2NLmZBu9mTJCuBwXeT9NcbtrDN6I8gKlkIPRySV0adOmbyipjSj9Gew\" width=\"120\">\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1zWzkMPyy22J98U4OBZIz_xinwhw8cPV_?usp=sharing)\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This beginner-friendly notebook shows you how to use Sutra's streaming feature with the OpenAI client. Streaming lets you see responses as they're being generated (word by word), instead of waiting for the complete response.\n",
        "\n",
        "### Why Use Streaming?\n",
        "\n",
        "- **Feels faster**: Users see text appearing immediately\n",
        "- **More interactive**: Creates a more natural conversation experience\n",
        "- **Better for long responses**: Users can start reading while the rest is being generated"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Your API Keys\n",
        "\n",
        "Before you begin, make sure you have:\n",
        "\n",
        "1. A SUTRA API key (Get yours at [TWO AI's SUTRA API page](https://www.two.ai/sutra/api))\n",
        "2. Basic familiarity with Python and Jupyter notebooks\n",
        "\n",
        "This notebook is designed to run in Google Colab, so no local Python installation is required."
      ],
      "metadata": {
        "id": "riab4RLjTdxV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtBCyHEePu_N"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Install necessary packages and set up the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_ctLxN6Pu_N"
      },
      "outputs": [],
      "source": [
        "# Install the OpenAI library\n",
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import necessary libraries\n"
      ],
      "metadata": {
        "id": "BAaRDR6QP79c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wv7kJHdPu_O"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authentication\n",
        "\n",
        "Set up authentication using Colab secrets."
      ],
      "metadata": {
        "id": "sywk8jK7QBXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get API key from Colab secrets\n",
        "api_key = userdata.get(\"SUTRA_API_KEY\")"
      ],
      "metadata": {
        "id": "UWw64B69QDW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize the client with SUTRA's API endpoint"
      ],
      "metadata": {
        "id": "O33sUi8eQFqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the client\n",
        "client = OpenAI(\n",
        "        base_url='https://api.two.ai/v2',\n",
        "        api_key=api_key\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dABjFS8QHfM",
        "outputId": "ea661859-2dca-4391-dbf2-7cd0e62e0462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI client initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyC3EwHTPu_O"
      },
      "source": [
        "## 2. Basic Streaming - Your First Example\n",
        "\n",
        "Let's create a simple function to stream responses from Sutra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ul883O5aPu_O"
      },
      "outputs": [],
      "source": [
        "def stream_response(prompt):\n",
        "    print(\"Streaming response...\")\n",
        "\n",
        "    stream = client.chat.completions.create(\n",
        "        model=\"sutra-v2\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7,\n",
        "        max_tokens=500,\n",
        "        stream=True\n",
        "    )\n",
        "\n",
        "    full_response = \"\"\n",
        "    for chunk in stream:\n",
        "        if chunk.choices[0].delta.content:\n",
        "            content = chunk.choices[0].delta.content\n",
        "            full_response += content\n",
        "            print(content, end=\"\", flush=True)\n",
        "\n",
        "    print(\"\\n\\n--- Done! ---\")\n",
        "    return full_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOBTeRSUPu_P"
      },
      "source": [
        "###Now let's try it with a simple question:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jPEM293Pu_P",
        "outputId": "baf1ed05-55a5-4a2c-c10d-033a5268a5b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streaming response...\n",
            "Artificial intelligence, or AI, is like a smart robot or computer that can think and learn a bit like humans do. Imagine you have a toy that can listen to you and answer your questions or play games with you. That’s similar to what AI does!\n",
            "\n",
            "AI can help with many things, like telling you the weather, helping doctors find out what's wrong with patients, or even making video games more fun by acting like real players. It learns from examples and information, so the more it practices, the better it gets at doing tasks, just like you get better at soccer the more you play!\n",
            "\n",
            "--- Done! ---\n"
          ]
        }
      ],
      "source": [
        "# Try our streaming function with a simple prompt\n",
        "prompt = \"Explain what artificial intelligence is to a 10-year old.\"\n",
        "response = stream_response(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X7UY-jDPu_P"
      },
      "source": [
        "## 3. Having a Conversation\n",
        "\n",
        "Now let's try having a back-and-forth conversation with streaming responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ARaGnzjPu_P"
      },
      "outputs": [],
      "source": [
        "def chat_with_streaming(messages):\n",
        "    \"\"\"Have a conversation with streaming responses\"\"\"\n",
        "    print(\"Streaming response...\")\n",
        "\n",
        "    stream = client.chat.completions.create(\n",
        "        model=\"sutra-v2\",\n",
        "        messages=messages,  # Pass the entire conversation history\n",
        "        temperature=0.7,\n",
        "        max_tokens=500,\n",
        "        stream=True\n",
        "    )\n",
        "\n",
        "    full_response = \"\"\n",
        "    for chunk in stream:\n",
        "        if chunk.choices[0].delta.content is not None:\n",
        "            content = chunk.choices[0].delta.content\n",
        "            full_response += content\n",
        "            print(content, end=\"\", flush=True)\n",
        "\n",
        "    print(\"\\n\\n--- Done! ---\")\n",
        "    return full_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCvy9SQYPu_P",
        "outputId": "a7520918-f608-4be3-d19a-115350691d7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: Tell me about some popular Indian street foods.\n",
            "\n",
            "Sutra: Streaming response...\n",
            "Indian street food is diverse and reflects the country's rich culinary heritage. Here are some popular options:\n",
            "\n",
            "1. **Pani Puri**: Also known as Golgappa or Phuchka, this dish consists of hollow, crispy puris filled with a spicy mixture of tamarind water, chickpeas, and potatoes.\n",
            "\n",
            "2. **Bhel Puri**: A savory snack made from puffed rice, vegetables, and tangy chutneys. It’s often garnished with sev (crispy noodles) and coriander.\n",
            "\n",
            "3. **Vada Pav**: A popular Mumbai street food, it features a spicy potato fritter (vada) placed in a bun (pav), often served with chutneys and fried green chilies.\n",
            "\n",
            "4. **Chaat**: This term encompasses various snacks, including Aloo Tikki Chaat (spicy potato patties with yogurt and chutneys) and Dahi Puri (small puris filled with yogurt and spices).\n",
            "\n",
            "5. **Samosa**: Triangular pastries filled with spiced potatoes, peas, and sometimes meat, usually deep-fried until golden brown. They are often served with tamarind or mint chutney.\n",
            "\n",
            "6. **Kathi Roll**: Originating from Kolkata, these are wraps filled with skewered meats or vegetables and topped with sauces and vegetables, all rolled in a paratha.\n",
            "\n",
            "7. **Dhokla**: A steamed savory cake made from fermented rice and chickpea flour, flavored with mustard seeds and green chilies. It’s often served with chutney.\n",
            "\n",
            "8. **Pav Bhaji**: A spicy vegetable mash served with buttered bread rolls (pav). The bhaji is made with mashed potatoes, tomatoes, and various spices.\n",
            "\n",
            "9. **Idli and Sambar**: While primarily a breakfast item, these steamed rice cakes (idli) served with a lentil soup (sambar) can also be found at street stalls.\n",
            "\n",
            "10. **Pesarattu**: A type of dosa made from green moong dal, typically served with ginger chutney or upma.\n",
            "\n",
            "These street foods not only represent the flavors of the region but also showcase the creativity and resourcefulness of local vendors.\n",
            "\n",
            "--- Done! ---\n",
            "\n",
            "You: Which one of these is your favorite and why?\n",
            "\n",
            "Sutra: Streaming response...\n",
            "As an AI, I don't have personal preferences or tastes. However, many people enjoy Pani Puri for its unique combination of textures and flavors. The contrast between the crispy puris and the spicy, tangy water, along with the filling of potatoes and chickpeas, makes it a favorite among street food lovers. Its interactive nature—where diners typically pop the puris into their mouths in one bite—adds to the fun and social aspect of enjoying this dish. Each region also has its own variation, which adds to its appeal and variety.\n",
            "\n",
            "--- Done! ---\n"
          ]
        }
      ],
      "source": [
        "# Start a conversation\n",
        "conversation = [\n",
        "    {\"role\": \"user\", \"content\": \"Tell me about some popular Indian street foods.\"}\n",
        "]\n",
        "\n",
        "# First message\n",
        "print(\"You: Tell me about some popular Indian street foods.\")\n",
        "print(\"\\nSutra: \", end=\"\")\n",
        "response = chat_with_streaming(conversation)\n",
        "\n",
        "# Add the response to our conversation history\n",
        "conversation.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "# Second message - follow up question\n",
        "conversation.append({\"role\": \"user\", \"content\": \"Which one of these is your favorite and why?\"})\n",
        "\n",
        "print(\"\\nYou: Which one of these is your favorite and why?\")\n",
        "print(\"\\nSutra: \", end=\"\")\n",
        "response = chat_with_streaming(conversation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJl6QmvvPu_Q"
      },
      "source": [
        "## 4. Simple Word Counter\n",
        "\n",
        "Let's create a simple example that counts words as they're being generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GpEuw65Pu_Q"
      },
      "outputs": [],
      "source": [
        "def simple_stream_with_word_count(prompt):\n",
        "    \"\"\"Stream response and display word count\"\"\"\n",
        "    print(\"Streaming response...\")\n",
        "\n",
        "    stream = client.chat.completions.create(\n",
        "        model=\"sutra-v2\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7,\n",
        "        max_tokens=500,\n",
        "        stream=True\n",
        "    )\n",
        "\n",
        "    full_response = \"\"\n",
        "\n",
        "    for chunk in stream:\n",
        "        if chunk.choices[0].delta.content is not None:\n",
        "            content = chunk.choices[0].delta.content\n",
        "            full_response += content\n",
        "            print(content, end=\"\", flush=True)\n",
        "\n",
        "    words = full_response.split()\n",
        "    print(f\"\\n\\n[Total words: {len(words)}]\")\n",
        "    print(\"--- Done! ---\")\n",
        "    return full_response"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try the word counter\n"
      ],
      "metadata": {
        "id": "DO3ONuM_RZ7y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvODfsycPu_Q",
        "outputId": "a9bd3e07-381e-4fc4-99df-464ee7969e65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streaming response...\n",
            "Clean water is essential for sustaining life, as it is crucial for human health, agriculture, and ecosystem balance. Access to safe drinking water prevents waterborne diseases, supports bodily functions, and contributes to overall well-being. In agriculture, clean water is vital for irrigation and livestock, ensuring food security and economic stability. Furthermore, healthy aquatic ecosystems rely on clean water to thrive, maintaining biodiversity and supporting various species. The importance of clean water underscores the need for sustainable management practices to protect this precious resource for future generations.\n",
            "\n",
            "[Total words: 86]\n",
            "--- Done! ---\n"
          ]
        }
      ],
      "source": [
        "# Try the word counter\n",
        "prompt = \"Write a short paragraph about the importance of clean water.\"\n",
        "response = simple_stream_with_word_count(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOaVoXg2Pu_Q"
      },
      "source": [
        "## 5. Handling Errors\n",
        "\n",
        "Let's create a simple function that handles errors when streaming."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYrp7G8kPu_Q"
      },
      "outputs": [],
      "source": [
        "def safe_stream(prompt):\n",
        "    \"\"\"Stream response with simple fallback on error\"\"\"\n",
        "    try:\n",
        "        print(\"Streaming response...\")\n",
        "        stream = client.chat.completions.create(\n",
        "            model=\"sutra-v2\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.7,\n",
        "            max_tokens=500,\n",
        "            stream=True\n",
        "        )\n",
        "\n",
        "        full_response = \"\"\n",
        "        for chunk in stream:\n",
        "            if chunk.choices[0].delta.content:\n",
        "                content = chunk.choices[0].delta.content\n",
        "                full_response += content\n",
        "                print(content, end=\"\", flush=True)\n",
        "\n",
        "        print(\"\\n\\n--- Done! ---\")\n",
        "        return full_response\n",
        "\n",
        "    except:\n",
        "        print(\"\\nError during streaming. Falling back...\")\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"sutra-v2\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.7,\n",
        "                max_tokens=500\n",
        "            )\n",
        "            result = response.choices[0].message.content\n",
        "            print(result)\n",
        "            print(\"\\n--- Done (fallback) ---\")\n",
        "            return result\n",
        "        except:\n",
        "            return \"Sorry, something went wrong. Please try again.\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try our error-handling function\n"
      ],
      "metadata": {
        "id": "y4WEGkDrRBUT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFxLoDMtPu_Q",
        "outputId": "88bda0f9-81eb-41fc-8793-7bcd058cb6f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streaming response...\n",
            "Transformer architecture is a type of neural network design primarily used for processing sequential data, such as text. Here are the main components explained simply:\n",
            "\n",
            "1. **Attention Mechanism**: Instead of processing data in order (like traditional models), transformers use attention to weigh the importance of different words in a sentence, allowing the model to focus on relevant parts of the input regardless of their position.\n",
            "\n",
            "2. **Self-Attention**: This is a specific type of attention where the model looks at all words in a sentence to understand how they relate to each other. For example, in the sentence \"The cat sat on the mat,\" the model can learn that \"cat\" and \"sat\" are related.\n",
            "\n",
            "3. **Positional Encoding**: Since transformers don't process data sequentially, they need a way to understand the order of words. Positional encodings are added to the input data to provide information about the position of each word in the sequence.\n",
            "\n",
            "4. **Multi-Head Attention**: This allows the model to have multiple attention mechanisms running in parallel, helping it to capture different relationships and aspects of the data simultaneously.\n",
            "\n",
            "5. **Feedforward Neural Networks**: After attention layers, the output is passed through feedforward neural networks, which help in further processing the information.\n",
            "\n",
            "6. **Stacked Layers**: Transformers consist of multiple layers of attention and feedforward networks stacked on top of each other to enhance learning capacity.\n",
            "\n",
            "7. **Encoder-Decoder Structure**: In many applications, transformers have an encoder to process the input data and a decoder to generate output. The encoder captures the context, while the decoder uses this context to produce relevant outputs.\n",
            "\n",
            "Overall, the transformer architecture enables more efficient training and better performance on tasks like translation, summarization, and more.\n",
            "\n",
            "--- Done! ---\n"
          ]
        }
      ],
      "source": [
        "# Try our error-handling function\n",
        "prompt = \"What is Transformer Architecture form in simple terms.\"\n",
        "response = safe_stream(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENGKpOgwPu_Q"
      },
      "source": [
        "## 6. Practical Example: Interactive Story\n",
        "\n",
        "Let's create a simple interactive story generator that you can try out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6DZ3TnGPu_R"
      },
      "outputs": [],
      "source": [
        "def interactive_story():\n",
        "    \"\"\"Simple interactive story generator\"\"\"\n",
        "    print(\"=== Interactive Story Generator ===\\n\")\n",
        "    print(\"Create a short story with your input.\")\n",
        "    print(\"You can guide the direction after each paragraph.\\n\")\n",
        "\n",
        "    # Ask for the initial story idea\n",
        "    story_idea = input(\"What should the story be about? \")\n",
        "\n",
        "    # Initialize the conversation\n",
        "    conversation = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a creative storyteller. Write vivid and engaging stories one paragraph at a time.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Write the first paragraph of a short story about {story_idea}. Keep it to 3–5 sentences.\"}\n",
        "    ]\n",
        "\n",
        "    # Generate the story in 3 parts\n",
        "    for i in range(3):\n",
        "        print(f\"\\n--- Paragraph {i + 1} ---\\n\")\n",
        "\n",
        "        # Generate and display the paragraph\n",
        "        response = chat_with_streaming(conversation)\n",
        "        conversation.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "        # Ask for user input to guide the next part\n",
        "        if i < 2:\n",
        "            direction = input(\"\\nWhat should happen next? \")\n",
        "            conversation.append({\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Continue the story with this idea: {direction}. Keep it to one paragraph (3–5 sentences).\"\n",
        "            })\n",
        "\n",
        "    print(\"\\n=== Story Complete! ===\")\n",
        "    return \"Story complete!\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# interactive story generator\n"
      ],
      "metadata": {
        "id": "F18JyX-GQviv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "Q0wc_1WwPu_R",
        "outputId": "5237988d-5ab1-4434-b9e0-91afaf0514de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Interactive Story Generator ===\n",
            "\n",
            "Create a short story with your input.\n",
            "You can guide the direction after each paragraph.\n",
            "\n",
            "What should the story be about? A lost cat in a big city\n",
            "\n",
            "--- Paragraph 1 ---\n",
            "\n",
            "Streaming response...\n",
            "Whiskers, a fluffy tabby with emerald green eyes, found herself perched on the edge of a bustling sidewalk in downtown Metroville, her heart racing amidst the cacophony of honking cars and chattering pedestrians. Just hours before, she had been curled up in the cozy warmth of her owner’s lap, but a curious flicker of movement had lured her out of the open window, leading to her unplanned adventure. The towering skyscrapers loomed like giants overhead, casting long shadows that seemed to swallow her whole as she took a hesitant step into a world filled with strange smells and unfamiliar sounds. With each cautious pawstep, Whiskers felt both exhilarated and frightened, an explorer in a vast urban jungle, desperately searching for a familiar face in the sea of strangers.\n",
            "\n",
            "--- Done! ---\n",
            "\n",
            "What should happen next? She meets a friendly dog who offers to help her\n",
            "\n",
            "--- Paragraph 2 ---\n",
            "\n",
            "Streaming response...\n",
            "As Whiskers hesitated, a jovial bark broke through the noise, and she turned to see a golden retriever bounding toward her, his tail wagging like a fluffy pendulum. \"Hey there, little furball! You look lost,\" he said, his voice warm and inviting, instantly easing her anxiety. With a friendly grin, he introduced himself as Max and offered to guide her back home, his keen nose twitching with determination. Whiskers, though initially wary, felt a spark of hope igniting within her; perhaps this friendly canine could help her navigate the sprawling maze of the city. Together, they set off, a mismatched duo ready to tackle whatever challenges lay ahead, united by the promise of friendship and the quest for safety.\n",
            "\n",
            "--- Done! ---\n",
            "\n",
            "What should happen next? They face danger in the tunnel from a gang of rats.\n",
            "\n",
            "--- Paragraph 3 ---\n",
            "\n",
            "Streaming response...\n",
            "As Whiskers and Max ventured deeper into the city, they stumbled upon a dark tunnel that promised a shortcut but also sent shivers down the tabby’s spine. Just as they entered, a scurrying sound echoed ominously around them, and a gang of rats emerged from the shadows, their beady eyes glinting with mischief and malice. “You’re not welcome here, furballs!” the largest rat taunted, his sharp teeth bared in a menacing grin. Whiskers's heart raced as she pressed closer to Max, who stood tall, growling protectively, ready to defend her against the advancing horde. In that tense moment, the duo knew they had to rely on each other; it was not just a fight for survival, but a test of their newfound friendship.\n",
            "\n",
            "--- Done! ---\n",
            "\n",
            "=== Story Complete! ===\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Story complete!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "interactive_story()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87dUUML9Pu_R"
      },
      "source": [
        "## 7. Conclusion\n",
        "\n",
        "Congratulations! You've learned the basics of using Sutra's streaming capabilities with the OpenAI client. Here's what we covered:\n",
        "\n",
        "1. **Basic setup** - How to connect to Sutra using the OpenAI client\n",
        "2. **Simple streaming** - Getting responses word by word\n",
        "3. **Conversations** - Having back-and-forth chats with streaming\n",
        "4. **Word counting** - A simple example of processing streamed content\n",
        "5. **Error handling** - Making your code more robust\n",
        "6. **Interactive stories** - A fun application of streaming\n",
        "\n",
        "\n",
        "Happy coding!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHOBxmatPu_R"
      },
      "source": [
        "## 8. Additional Resources\n",
        "\n",
        "- [Sutra Documentation](https://docs.sutra.ai)\n",
        "- [OpenAI API Documentation](https://platform.openai.com/docs)\n",
        "- [OpenAI Streaming Guide](https://platform.openai.com/docs/api-reference/streaming)\n",
        "\n",
        "For more examples, check out other notebooks in the Sutra Cookbooks repository."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}