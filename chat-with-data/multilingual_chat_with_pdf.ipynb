{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joReEVmEQKK5"
      },
      "source": [
        "# \ud83d\udcda Multilingual Chat with PDF (Powered by SUTRA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMvVqesEZ9pY"
      },
      "source": [
        "<div style=\"display: flex; align-items: center; gap: 40px;\">\n",
        "\n",
        "<img src=\"https://play-lh.googleusercontent.com/_O9p4Z4yucA2NLmZBu9mTJCuBwXeT9NcbtrDN6I8gKlkIPRySV0adOmbyipjSj9Gew\" width=\"130\">\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/18BffQ6e0xrIpF97jRniLci2mAEvxHSl7?usp=sharing)\n",
        "\n",
        "\n",
        "<div>\n",
        "  <h2>SUTRA by TWO Platforms</h2>\n",
        "  <p>SUTRA is a family of large multi-lingual language (LMLMs) models pioneered by Two Platforms. SUTRA\u2019s dual-transformer approach extends the power of both MoE and Dense AI language model architectures, delivering cost-efficient multilingual capabilities for over 50+ languages. It powers scalable AI applications for conversation, search, and advanced reasoning, ensuring high-performance across diverse languages, domains and applications.</p>\n",
        "\n",
        "</div>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGL1As_GaIt-"
      },
      "source": [
        "## Get Your API Keys\n",
        "\n",
        "Before you begin, make sure you have:\n",
        "\n",
        "1. A SUTRA API key (Get yours at [TWO AI's SUTRA API page](https://www.two.ai/sutra/api))\n",
        "2. Basic familiarity with Python and Jupyter notebooks\n",
        "\n",
        "This notebook is designed to run in Google Colab, so no local Python installation is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uQQHhIiN3CH"
      },
      "source": [
        "### 1. Install Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nPoxsbOLSoQ",
        "outputId": "d19adb48-79c6-4ed2-ac42-eadd182a0162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/62.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain_openai langchain-community faiss-cpu requests pypdf python-docx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6HKziXMN6-2"
      },
      "source": [
        "### STEP 2 : Setup API Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcNUI6fWLZ0i"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set the API key from Colab secrets\n",
        "os.environ[\"SUTRA_API_KEY\"] = userdata.get(\"SUTRA_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJqLPi81OBVR"
      },
      "source": [
        "### STEP 3 :  Load the PDF Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpZ58RjuLfeC",
        "outputId": "fdeecbce-263a-4e16-f5c7-81e22bafc45b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 15 pages.\n"
          ]
        }
      ],
      "source": [
        "# \ud83d\udccd STEP 3: Load the PDF Document (replace 'example.pdf' as needed)\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/NIPS-2017-attention-is-all-you-need-Paper.pdf\")\n",
        "documents = loader.load()\n",
        "print(f\"Loaded {len(documents)} pages.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdiY8_hpOPjp"
      },
      "source": [
        "### STEP 4 :  Split Documents into Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xRJTvRSLx6U",
        "outputId": "5cbd7c99-7758-4f84-f53c-86021b29f71a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split into 49 chunks.\n"
          ]
        }
      ],
      "source": [
        "# \ud83d\udccd STEP 4: Split Documents into Chunks\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100\n",
        ")\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "print(f\"Split into {len(chunks)} chunks.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGZNvievOVz4"
      },
      "source": [
        "###STEP 5 :  Create Embeddings + FAISS Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShVnNGD1L1Nf"
      },
      "outputs": [],
      "source": [
        "# \ud83d\udccd STEP 5: Create Embeddings + FAISS Vector Store\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGDRWRNGOaMT"
      },
      "source": [
        "###STEP 6 :  Set Up Conversation Memory and RAG Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYFEFqY4MOYy",
        "outputId": "35eec509-c9d5-4140-a551-eb6805f8ba60"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-fc5334be7585>:6: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(\n"
          ]
        }
      ],
      "source": [
        "# \ud83d\udccd STEP 6: Set Up Conversation Memory and RAG Chain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True\n",
        ")\n",
        "\n",
        "# RAG model using Sutra\n",
        "rag_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=ChatOpenAI(\n",
        "        api_key=os.getenv(\"SUTRA_API_KEY\"),\n",
        "        base_url=\"https://api.two.ai/v2\",\n",
        "        model=\"sutra-v2\",\n",
        "        temperature=0.5\n",
        "    ),\n",
        "    retriever=retriever,\n",
        "    memory=memory\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PXjWo34Og9W"
      },
      "source": [
        "###STEP 7 :  Ask Questions (Supports Multiple Languages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eo8C8HTMUzI"
      },
      "outputs": [],
      "source": [
        "# \ud83d\udccd STEP 7: Ask Questions (Supports Multiple Languages)\n",
        "def ask_question(question, language=\"English\"):\n",
        "    rag_response = rag_chain.invoke(question)\n",
        "    context = rag_response[\"answer\"]\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are a helpful assistant that answers questions about documents.\n",
        "    Use the following context to answer the question:\n",
        "\n",
        "    CONTEXT:\n",
        "    {context}\n",
        "\n",
        "    Please respond in {language}.\n",
        "\n",
        "    Question: {question}\n",
        "    \"\"\"\n",
        "\n",
        "    chat = ChatOpenAI(\n",
        "        api_key=os.getenv(\"SUTRA_API_KEY\"),\n",
        "        base_url=\"https://api.two.ai/v2\",\n",
        "        model=\"sutra-v2\",\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    from langchain.schema import HumanMessage\n",
        "    response = chat.invoke([HumanMessage(content=prompt)])\n",
        "    return response.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dm4JfHOOo79"
      },
      "source": [
        "###STEP 8: Try It Out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASF6fpBUMakG",
        "outputId": "f26ff0e0-54e0-4dc5-b06c-6e330b9e29f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udd39 Response:\n",
            " Transformer \u090f\u0915 \u0928\u094d\u092f\u0942\u0930\u0932 \u0928\u0947\u091f\u0935\u0930\u094d\u0915 \u0906\u0930\u094d\u0915\u093f\u091f\u0947\u0915\u094d\u091a\u0930 \u0939\u0948 \u091c\u094b \u092a\u0942\u0930\u0940 \u0924\u0930\u0939 \u0938\u0947 \u0927\u094d\u092f\u093e\u0928 \u0924\u0902\u0924\u094d\u0930 (attention mechanisms) \u092a\u0930 \u0928\u093f\u0930\u094d\u092d\u0930 \u0915\u0930\u0924\u093e \u0939\u0948, \u091c\u093f\u0938\u0938\u0947 \u092a\u0941\u0928\u0930\u093e\u0935\u0943\u0924\u094d\u0924 (recurrent) \u092f\u093e \u0938\u0902\u0915\u0941\u091a\u0928 (convolutional) \u092a\u0930\u0924\u094b\u0902 \u0915\u0940 \u0906\u0935\u0936\u094d\u092f\u0915\u0924\u093e \u0938\u092e\u093e\u092a\u094d\u0924 \u0939\u094b \u091c\u093e\u0924\u0940 \u0939\u0948\u0964 \u0907\u0938\u0947 2017 \u092e\u0947\u0902 \u0935\u093e\u0938\u0935\u093e\u0928\u0940 \u0914\u0930 \u0905\u0928\u094d\u092f \u0926\u094d\u0935\u093e\u0930\u093e \u0932\u093f\u0916\u0940 \u0917\u0908 \u092a\u0924\u094d\u0930 \"Attention Is All You Need\" \u092e\u0947\u0902 \u092a\u0947\u0936 \u0915\u093f\u092f\u093e \u0917\u092f\u093e \u0925\u093e\u0964 \n",
            "\n",
            "Transformer \u092e\u0949\u0921\u0932 \u090f\u0915 \u090f\u0928\u0915\u094b\u0921\u0930-\u0921\u0940\u0915\u094b\u0921\u0930 \u0938\u0902\u0930\u091a\u0928\u093e \u092e\u0947\u0902 \u0939\u094b\u0924\u093e \u0939\u0948, \u091c\u0939\u093e\u0901:\n",
            "\n",
            "- **\u090f\u0928\u0915\u094b\u0921\u0930** \u0907\u0928\u092a\u0941\u091f \u0905\u0928\u0941\u0915\u094d\u0930\u092e \u0915\u094b \u092a\u094d\u0930\u094b\u0938\u0947\u0938 \u0915\u0930\u0924\u093e \u0939\u0948 \u0914\u0930 \u0928\u093f\u0930\u0902\u0924\u0930 \u092a\u094d\u0930\u0924\u093f\u0928\u093f\u0927\u093f\u0924\u094d\u0935 (continuous representations) \u0909\u0924\u094d\u092a\u0928\u094d\u0928 \u0915\u0930\u0924\u093e \u0939\u0948\u0964\n",
            "- **\u0921\u0940\u0915\u094b\u0921\u0930** \u0907\u0928 \u092a\u094d\u0930\u0924\u093f\u0928\u093f\u0927\u093f\u092f\u094b\u0902 \u0915\u094b \u0932\u0947\u0924\u093e \u0939\u0948 \u0914\u0930 \u0906\u0909\u091f\u092a\u0941\u091f \u0905\u0928\u0941\u0915\u094d\u0930\u092e \u0915\u094b \u090f\u0915 \u0938\u092e\u092f \u092e\u0947\u0902 \u090f\u0915 \u0924\u0924\u094d\u0935 \u0915\u0947 \u0930\u0942\u092a \u092e\u0947\u0902 \u0909\u0924\u094d\u092a\u0928\u094d\u0928 \u0915\u0930\u0924\u093e \u0939\u0948, \u092a\u0939\u0932\u0947 \u0938\u0947 \u0909\u0924\u094d\u092a\u0928\u094d\u0928 \u092a\u094d\u0930\u0924\u0940\u0915\u094b\u0902 \u0915\u093e \u0909\u092a\u092f\u094b\u0917 \u0915\u0930\u0924\u0947 \u0939\u0941\u090f\u0964\n",
            "\n",
            "Transformer \u0915\u0940 \u092a\u094d\u0930\u092e\u0941\u0916 \u0935\u093f\u0936\u0947\u0937\u0924\u093e\u090f\u0901 \u0939\u0948\u0902:\n",
            "\n",
            "1. **\u0938\u0947\u0932\u094d\u092b-\u0905\u091f\u0947\u0902\u0936\u0928 \u0924\u0902\u0924\u094d\u0930**: \u092f\u0939 \u092e\u0949\u0921\u0932 \u0915\u094b \u0935\u093e\u0915\u094d\u092f \u092e\u0947\u0902 \u0935\u093f\u092d\u093f\u0928\u094d\u0928 \u0936\u092c\u094d\u0926\u094b\u0902 \u0915\u0947 \u092e\u0939\u0924\u094d\u0935 \u0915\u094b \u090f\u0915 \u0926\u0942\u0938\u0930\u0947 \u0915\u0947 \u0938\u093e\u092a\u0947\u0915\u094d\u0937 \u092e\u093e\u092a\u0928\u0947 \u0915\u0940 \u0905\u0928\u0941\u092e\u0924\u093f \u0926\u0947\u0924\u093e \u0939\u0948, \u091a\u093e\u0939\u0947 \u0935\u0947 \u0905\u0928\u0941\u0915\u094d\u0930\u092e \u092e\u0947\u0902 \u0915\u093f\u0924\u0928\u0940 \u092d\u0940 \u0926\u0942\u0930 \u0915\u094d\u092f\u094b\u0902 \u0928 \u0939\u094b\u0902\u0964 \u092f\u0939 \u0936\u092c\u094d\u0926\u094b\u0902 \u0915\u0947 \u092c\u0940\u091a \u0938\u0902\u092c\u0902\u0927\u094b\u0902 \u0914\u0930 \u0928\u093f\u0930\u094d\u092d\u0930\u0924\u093e\u0913\u0902 \u0915\u094b \u092a\u0915\u0921\u093c\u0928\u0947 \u0915\u0947 \u0932\u093f\u090f \u092e\u0939\u0924\u094d\u0935\u092a\u0942\u0930\u094d\u0923 \u0939\u0948\u0964\n",
            "\n",
            "2. **\u092e\u0932\u094d\u091f\u0940-\u0939\u0947\u0921\u0947\u0921 \u0905\u091f\u0947\u0902\u0936\u0928**: \u0915\u0908 \u0927\u094d\u092f\u093e\u0928 \u0924\u0902\u0924\u094d\u0930 \u0938\u092e\u093e\u0928\u093e\u0902\u0924\u0930 \u092e\u0947\u0902 \u091a\u0932\u0924\u0947 \u0939\u0948\u0902, \u091c\u093f\u0938\u0938\u0947 \u092e\u0949\u0921\u0932 \u0907\u0928\u092a\u0941\u091f \u0915\u0947 \u0935\u093f\u092d\u093f\u0928\u094d\u0928 \u092d\u093e\u0917\u094b\u0902 \u092a\u0930 \u090f\u0915 \u0938\u093e\u0925 \u0927\u094d\u092f\u093e\u0928 \u0915\u0947\u0902\u0926\u094d\u0930\u093f\u0924 \u0915\u0930 \u0938\u0915\u0924\u093e \u0939\u0948\u0964\n",
            "\n",
            "3. **\u092a\u0948\u0930\u0947\u0932\u0932\u093e\u0907\u091c\u0947\u0936\u0928**: \u092a\u0941\u0928\u0930\u093e\u0935\u0943\u0924\u094d\u0924 \u092e\u0949\u0921\u0932\u094b\u0902 \u0915\u0947 \u0935\u093f\u092a\u0930\u0940\u0924, \u091c\u094b \u0905\u0928\u0941\u0915\u094d\u0930\u092e\u094b\u0902 \u0915\u094b \u0915\u094d\u0930\u092e\u093f\u0915 \u0930\u0942\u092a \u0938\u0947 \u092a\u094d\u0930\u094b\u0938\u0947\u0938 \u0915\u0930\u0924\u0947 \u0939\u0948\u0902, Transformers \u092a\u0942\u0930\u0947 \u0905\u0928\u0941\u0915\u094d\u0930\u092e\u094b\u0902 \u0915\u094b \u090f\u0915 \u0938\u093e\u0925 \u092a\u094d\u0930\u094b\u0938\u0947\u0938 \u0915\u0930 \u0938\u0915\u0924\u0947 \u0939\u0948\u0902, \u091c\u093f\u0938\u0938\u0947 \u092a\u094d\u0930\u0936\u093f\u0915\u094d\u0937\u0923 \u0915\u0940 \u0917\u0924\u093f \u0914\u0930 \u0926\u0915\u094d\u0937\u0924\u093e \u092e\u0947\u0902 \u092e\u0939\u0924\u094d\u0935\u092a\u0942\u0930\u094d\u0923 \u0938\u0941\u0927\u093e\u0930 \u0939\u094b\u0924\u093e \u0939\u0948\u0964\n",
            "\n",
            "4. **\u0930\u093e\u091c\u094d\u092f-\u0915\u0947-\u0930\u093e\u091c\u094d\u092f \u092a\u094d\u0930\u0926\u0930\u094d\u0936\u0928**: Transformer \u0928\u0947 \u0935\u093f\u092d\u093f\u0928\u094d\u0928 \u092a\u094d\u0930\u093e\u0915\u0943\u0924\u093f\u0915 \u092d\u093e\u0937\u093e \u092a\u094d\u0930\u0938\u0902\u0938\u094d\u0915\u0930\u0923 \u0915\u093e\u0930\u094d\u092f\u094b\u0902 \u092e\u0947\u0902 \u0930\u093e\u091c\u094d\u092f-\u0915\u0947-\u0930\u093e\u091c\u094d\u092f \u092a\u0930\u093f\u0923\u093e\u092e \u092a\u094d\u0930\u093e\u092a\u094d\u0924 \u0915\u093f\u090f \u0939\u0948\u0902, \u091c\u0948\u0938\u0947 \u092e\u0936\u0940\u0928 \u0905\u0928\u0941\u0935\u093e\u0926, \u091c\u093f\u0938\u0938\u0947 \u092f\u0939 \u092a\u0941\u0928\u0930\u093e\u0935\u0943\u0924\u094d\u0924 \u092f\u093e \u0938\u0902\u0915\u0941\u091a\u0928 \u0906\u0930\u094d\u0915\u093f\u091f\u0947\u0915\u094d\u091a\u0930 \u092a\u0930 \u0906\u0927\u093e\u0930\u093f\u0924 \u092a\u093f\u091b\u0932\u0947 \u092e\u0949\u0921\u0932\u094b\u0902 \u0915\u094b \u092a\u0940\u091b\u0947 \u091b\u094b\u0921\u093c \u0926\u0947\u0924\u093e \u0939\u0948\u0964\n",
            "\n",
            "\u0915\u0941\u0932 \u092e\u093f\u0932\u093e\u0915\u0930, Transformer \u0906\u0930\u094d\u0915\u093f\u091f\u0947\u0915\u094d\u091a\u0930 \u0906\u0927\u0941\u0928\u093f\u0915 \u0917\u0939\u0930\u0940 \u0938\u0940\u0916\u0928\u0947 \u0915\u0947 \u0905\u0928\u0941\u092a\u094d\u0930\u092f\u094b\u0917\u094b\u0902 \u092e\u0947\u0902 \u090f\u0915 \u092e\u094c\u0932\u093f\u0915 \u0906\u0927\u093e\u0930 \u092c\u0928 \u0917\u092f\u093e \u0939\u0948\u0964\n"
          ]
        }
      ],
      "source": [
        "# \ud83d\udccd STEP 8: Try It Out!\n",
        "response = ask_question(\"what is transformer\", language=\"Hindi\")\n",
        "print(\"\ud83d\udd39 Response:\\n\", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kFNYjZeOujB"
      },
      "source": [
        "##Finally Integrated UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490,
          "referenced_widgets": [
            "f1ff83b70fdd49a4916cb7b296c0e78e",
            "936845a96593421797289fa20733a6a7",
            "28691eacbf0e4b24bb8a7996cd0faa51",
            "a9c8ed7564854afdbb1cb917bd31f9a1",
            "57a2dc693edc439a9cc21b407f8a8122",
            "778b4cc3bfb740d6adf544ff071aba17",
            "ee6b3b899e3d4e6f8def68470abc4583",
            "d84d384ccb5a46148f2ecd3a610c54a4",
            "d030517a5ec94d93a094acd8dd663e26",
            "717d1e582b15493c8b96f48e5b2e798a",
            "a3ae2f9e741444149a0d94d098341638",
            "628aff5227c8414aba2fef292f785a91",
            "abd9f2d613d34e24a385a79f25de8608",
            "d338366d8471451981d3891823f2f6d5",
            "1c312031cd37450884e7f59c028989af",
            "6b7d5493d192465ba201aa5e45cb5226",
            "ef4243380ef24f61b6294dd4a4ff2c53",
            "8250627b7bc3453ab8b88ac29e484ae2",
            "b3f275d0f8ef42f0978a0cffe5ccc40c",
            "623a3a1edde4499ba81ae9da3c69d39d",
            "532ab4b2b3904ac7988dbf074d834eeb",
            "0c8fab512c814a26b46c5df397706931",
            "7f4b259817524dd3a415cffcea794ee8",
            "2051a7efb9c34baea9e9fcca9e27399c",
            "77cb84bba13e45359772e5702ee6504a",
            "92f5f5e71bfb4fca9d5a762ac6f80a69",
            "02c6a8b7868b48a3984640492cb24d3b",
            "6a34d03adda94e2c9df6439aec967360",
            "b8c6a87ed173496a81b43ed1380132ee"
          ]
        },
        "id": "v7ENw2ZJM9iV",
        "outputId": "be9243e6-3193-4f4a-f9b9-0aea0245fffa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1ff83b70fdd49a4916cb7b296c0e78e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value=\"<h3 style='font-family:Arial;'>\ud83d\udcda Multilingual Chat with PDF (Upload from Local)</h3\u2026"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 1. Imports\n",
        "import os\n",
        "import requests\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.schema import HumanMessage\n",
        "from tempfile import NamedTemporaryFile\n",
        "\n",
        "# 2. Setup LLM (Sutra)\n",
        "def get_sutra_model():\n",
        "    return ChatOpenAI(\n",
        "        api_key=os.getenv(\"SUTRA_API_KEY\"),\n",
        "        base_url=\"https://api.two.ai/v2\",\n",
        "        model=\"sutra-v2\",\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "# 3. Load and index PDF\n",
        "def load_and_index_pdf(pdf_path):\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    docs = loader.load()\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "    chunks = text_splitter.split_documents(docs)\n",
        "\n",
        "    embeddings = OpenAIEmbeddings(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "    vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "    chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=get_sutra_model(),\n",
        "        retriever=vectorstore.as_retriever(),\n",
        "        memory=memory\n",
        "    )\n",
        "    return chain\n",
        "\n",
        "# 4. UI Components\n",
        "\n",
        "# PDF File Upload widget\n",
        "pdf_file_upload = widgets.FileUpload(\n",
        "    accept='.pdf',\n",
        "    multiple=False,\n",
        "    description='\ud83d\udcc1 Upload PDF',\n",
        "    layout=widgets.Layout(width='300px')\n",
        ")\n",
        "\n",
        "load_pdf_button = widgets.Button(\n",
        "    description=\"\ud83d\udd04 Load PDF\",\n",
        "    button_style='info',\n",
        "    layout=widgets.Layout(width='150px')\n",
        ")\n",
        "\n",
        "status_output = widgets.Output()\n",
        "\n",
        "# Language dropdown\n",
        "languages = [\n",
        "    \"English\", \"Hindi\", \"Gujarati\", \"Bengali\", \"Tamil\",\n",
        "    \"Telugu\", \"Kannada\", \"Malayalam\", \"Punjabi\", \"Marathi\",\n",
        "    \"Urdu\", \"Assamese\", \"Odia\", \"Sanskrit\", \"Korean\",\n",
        "    \"Japanese\", \"Arabic\", \"French\", \"German\", \"Spanish\",\n",
        "    \"Portuguese\", \"Russian\", \"Chinese\", \"Vietnamese\", \"Thai\",\n",
        "    \"Indonesian\", \"Turkish\", \"Polish\", \"Ukrainian\", \"Dutch\",\n",
        "    \"Italian\", \"Greek\", \"Hebrew\", \"Persian\", \"Swedish\",\n",
        "    \"Norwegian\", \"Danish\", \"Finnish\", \"Czech\", \"Hungarian\",\n",
        "    \"Romanian\", \"Bulgarian\", \"Croatian\", \"Serbian\", \"Slovak\",\n",
        "    \"Slovenian\", \"Estonian\", \"Latvian\", \"Lithuanian\", \"Malay\",\n",
        "    \"Tagalog\", \"Swahili\"\n",
        "]\n",
        "\n",
        "lang_dropdown = widgets.Dropdown(\n",
        "    options=languages,\n",
        "    value=\"English\",\n",
        "    description='\ud83c\udf10 Language:',\n",
        "    layout=widgets.Layout(width='300px')\n",
        ")\n",
        "\n",
        "chat_output = widgets.HTML(\n",
        "    value=\"<div style='padding:10px; font-family:Arial; font-size:14px; height:300px; overflow-y:auto; border:1px solid #ccc; border-radius:5px;'>Chat history will appear here...</div>\"\n",
        ")\n",
        "\n",
        "user_input = widgets.Text(\n",
        "    placeholder='Type your message...',\n",
        "    layout=widgets.Layout(flex='4', width='auto')\n",
        ")\n",
        "\n",
        "send_button = widgets.Button(\n",
        "    description=\"\ud83d\udce4 Send\",\n",
        "    button_style='primary',\n",
        "    layout=widgets.Layout(flex='1', width='auto')\n",
        ")\n",
        "\n",
        "messages = []\n",
        "conversation_chain = None\n",
        "\n",
        "# 5. Load PDF Logic\n",
        "def on_load_pdf(b):\n",
        "    global conversation_chain\n",
        "    uploaded_files = pdf_file_upload.value\n",
        "\n",
        "    with status_output:\n",
        "        clear_output()\n",
        "        if not uploaded_files:\n",
        "            print(\"\u274c Please upload a PDF file first.\")\n",
        "            return\n",
        "        try:\n",
        "            print(\"\u23f3 Processing uploaded PDF...\")\n",
        "\n",
        "            # Save uploaded content to a temp file\n",
        "            uploaded_file = list(uploaded_files.values())[0]\n",
        "            with NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp:\n",
        "                tmp.write(uploaded_file['content'])\n",
        "                tmp_path = tmp.name\n",
        "\n",
        "            conversation_chain = load_and_index_pdf(tmp_path)\n",
        "            print(\"\u2705 PDF loaded and indexed successfully!\")\n",
        "        except Exception as e:\n",
        "            print(\"\u274c Error:\", e)\n",
        "\n",
        "load_pdf_button.on_click(on_load_pdf)\n",
        "\n",
        "# 6. Chat Interaction Logic\n",
        "def on_send_click(b):\n",
        "    global conversation_chain\n",
        "    if conversation_chain is None:\n",
        "        with status_output:\n",
        "            clear_output()\n",
        "            print(\"\u274c Load a PDF first.\")\n",
        "        return\n",
        "\n",
        "    user_text = user_input.value.strip()\n",
        "    if not user_text:\n",
        "        return\n",
        "\n",
        "    lang = lang_dropdown.value\n",
        "    messages.append(f\"<b style='color:#13f22d;'>You:</b> {user_text}\")\n",
        "\n",
        "    context_response = conversation_chain.invoke(user_text)\n",
        "    rag_context = context_response['answer']\n",
        "\n",
        "    system_msg = f\"\"\"\n",
        "You are a helpful assistant answering based on a document.\n",
        "Use this context: {rag_context}\n",
        "Always reply in: {lang}\n",
        "Question: {user_text}\n",
        "\"\"\"\n",
        "\n",
        "    chat_model = get_sutra_model()\n",
        "    sutra_response = chat_model.invoke([HumanMessage(content=system_msg)])\n",
        "    assistant_reply = sutra_response.content.strip()\n",
        "\n",
        "    messages.append(f\"<b style='color:#007acc;'>Assistant ({lang}):</b> {assistant_reply}\")\n",
        "\n",
        "    chat_html = \"<br>\".join(messages)\n",
        "    chat_output.value = f\"<div style='padding:10px; font-family:Arial; font-size:14px; height:300px; overflow-y:auto; border:1px solid #ccc; border-radius:5px;'>{chat_html}</div>\"\n",
        "\n",
        "    user_input.value = \"\"\n",
        "\n",
        "send_button.on_click(on_send_click)\n",
        "\n",
        "# 7. Final Layout\n",
        "input_row = widgets.HBox([user_input, send_button])\n",
        "pdf_row = widgets.HBox([pdf_file_upload, load_pdf_button])\n",
        "\n",
        "ui = widgets.VBox([\n",
        "    widgets.HTML(\"<h3 style='font-family:Arial;'>\ud83d\udcda Multilingual Chat with PDF (Upload from Local)</h3>\"),\n",
        "    pdf_row,\n",
        "    lang_dropdown,\n",
        "    chat_output,\n",
        "    input_row,\n",
        "    status_output\n",
        "])\n",
        "\n",
        "# 8. Display the App\n",
        "display(ui)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}