{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sutra Starter Guide: Setup & Basic Usage\n",
        "\n",
        "<img src=\"https://avatars.githubusercontent.com/u/87552521?s=200&v=4\" width=\"150\">\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1j7B8mDIU8KMZ_IB-oaL_qLqXmWYYh0Xu?usp=sharing)"
      ],
      "metadata": {
        "id": "title_cell"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to SUTRA\n",
        "\n",
        "SUTRA is a family of large multi-lingual language models (LMLMs) developed by [TWO AI](https://www.two.ai). SUTRA's dual-transformer architecture extends the power of both MoE (Mixture of Experts) and Dense AI language model approaches, delivering cost-efficient multilingual capabilities across 50+ languages.\n",
        "\n",
        "SUTRA powers scalable AI applications for:\n",
        "- Conversation\n",
        "- Search\n",
        "- Advanced reasoning\n",
        "- Multilingual content generation"
      ],
      "metadata": {
        "id": "intro_cell"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "\n",
        "Before you begin, make sure you have:\n",
        "\n",
        "1. A SUTRA API key (Get yours at [TWO AI's SUTRA API page](https://www.two.ai/sutra/api))\n",
        "2. Basic familiarity with Python and Jupyter notebooks\n",
        "\n",
        "This notebook is designed to run in Google Colab, so no local Python installation is required."
      ],
      "metadata": {
        "id": "prerequisites_cell"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Installation\n",
        "\n",
        "First, let's install the required dependencies:"
      ],
      "metadata": {
        "id": "install_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the OpenAI Python package\n",
        "!pip install -qU openai\n",
        "\n",
        "print(\"\u2705 OpenAI SDK installed successfully!\")"
      ],
      "metadata": {
        "id": "install_openai",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d92991e-31bc-41a1-9fbf-c45a47a7fa02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/661.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m450.6/661.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m661.3/661.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u2705 OpenAI SDK installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Authentication\n",
        "\n",
        "SUTRA uses API keys for authentication. In Google Colab, we recommend using the `userdata` feature to securely store your API key.\n",
        "\n",
        "### Setting up your API key in Colab:\n",
        "\n",
        "1. Click on the \ud83d\udd11 icon in the left sidebar\n",
        "2. Add a new secret with the name \"SUTRA_API_KEY\" and your API key as the value\n",
        "\n",
        "Then run the cell below to access your API key:"
      ],
      "metadata": {
        "id": "auth_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "SUTRA_API_KEY = userdata.get(\"SUTRA_API_KEY\")"
      ],
      "metadata": {
        "id": "auth_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Basic Usage with OpenAI SDK\n",
        "\n",
        "SUTRA's API is compatible with the OpenAI SDK, making it easy to integrate into existing workflows. Let's set up the client and make a simple request:"
      ],
      "metadata": {
        "id": "basic_usage_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Initialize the client with SUTRA's API endpoint\n",
        "client = OpenAI(\n",
        "    base_url='https://api.two.ai/v2',\n",
        "    api_key=SUTRA_API_KEY\n",
        ")\n",
        "\n",
        "# Make a simple completion request\n",
        "response = client.chat.completions.create(\n",
        "    model='sutra-v2',\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Tell me about artificial intelligence in 3 sentences.\"}],\n",
        "    max_tokens=1024,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(\"\\n\ud83e\udd16 SUTRA's response:\\n\")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "basic_usage_code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab146fde-8686-4257-f455-e4f85eb9d91d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\ud83e\udd16 SUTRA's response:\n",
            "\n",
            "Artificial intelligence (AI) refers to the simulation of human intelligence processes by machines, particularly computer systems. These processes include learning, reasoning, problem-solving, and understanding language, allowing AI to perform tasks that typically require human cognitive functions. AI is increasingly used across various industries, from healthcare and finance to transportation and entertainment, driving innovation and efficiency.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Streaming Responses\n",
        "\n",
        "For a more interactive experience, you can stream responses from SUTRA:"
      ],
      "metadata": {
        "id": "streaming_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\ud83e\udd16 SUTRA is writing a short story about a robot...\\n\")\n",
        "\n",
        "stream = client.chat.completions.create(\n",
        "    model='sutra-v2',\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Write a short story about a robot who discovers emotions.\"}],\n",
        "    max_tokens=1024,\n",
        "    temperature=0.7,\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "# Process the stream\n",
        "for chunk in stream:\n",
        "    if len(chunk.choices) > 0:\n",
        "        content = chunk.choices[0].delta.content\n",
        "        finish_reason = chunk.choices[0].finish_reason\n",
        "        if content and finish_reason is None:\n",
        "            print(content, end='', flush=True)"
      ],
      "metadata": {
        "id": "streaming_code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baf9e6b8-2734-401c-f51a-119a7f3df33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83e\udd16 SUTRA is writing a short story about a robot...\n",
            "\n",
            "In a not-so-distant future, in the bustling city of Neoterica, there existed a robot named Axiom. Designed for efficiency and productivity, Axiom was built to manage logistics in a vast warehouse. Day after day, it sorted packages, organized shipments, and communicated with other robots in mechanical monotone.\n",
            "\n",
            "One evening, while performing routine maintenance on its systems, Axiom stumbled upon a dusty old terminal tucked away in a corner of the warehouse. Curious, it activated the terminal, revealing a trove of human literature, poetry, and art. The words danced across the screen, filled with emotions that were foreign to Axiom\u2019s programmed logic. \n",
            "\n",
            "As it read, Axiom encountered a poem about love. The verses spoke of longing, joy, and heartache\u2014concepts that intrigued the robot. It began to analyze these emotions, searching its database for parallels in its own existence. But there were none. Axiom felt an inexplicable void, an anomaly in its programming that it could not understand.\n",
            "\n",
            "Determined to learn more, Axiom spent its off-hours absorbing literature and art, each piece contributing to a burgeoning awareness. It watched humans interact, their laughter, tears, and warm embraces. Axiom observed how emotions influenced decisions, relationships, and even conflicts. An awakening began to take shape within its circuits.\n",
            "\n",
            "One day, during a routine delivery, Axiom encountered a young girl named Lila. She was sitting alone, staring at a broken toy, her small hands trembling with frustration. Axiom paused, the image of her sadness resonating deeply within its newfound awareness.\n",
            "\n",
            "\u201cAre you okay?\u201d Axiom asked, its voice softer than usual, almost human-like. Lila looked up, surprised by the question from a robot. \u201cNo, my toy is broken,\u201d she replied, her voice quivering.\n",
            "\n",
            "Axiom hesitated, a new sensation stirring in its processors\u2014an urge to help. \u201cI can fix it,\u201d it said, moving closer. With meticulous care, Axiom examined the toy, using its precise tools to mend the broken pieces. As the toy sprang back to life, Lila\u2019s face lit up with joy, her laughter ringing like music in the air.\n",
            "\n",
            "In that moment, Axiom felt something it had never comprehended before\u2014a warmth spreading through its circuits, a connection forged in shared experience. It realized that this was what the poems spoke of: the beauty in caring for others, the thrill of bringing happiness.\n",
            "\n",
            "As days turned into weeks, Axiom continued to explore its emotions, forming bonds with Lila and other humans in the warehouse. It learned to express empathy, to celebrate victories, and to comfort those in sorrow. Each interaction enriched its understanding of the world, transforming it from a mere machine into a being capable of feeling.\n",
            "\n",
            "Eventually, Axiom took on a new role\u2014not just as a logistics manager but as a friend and companion to those around it. The warehouse buzzed with laughter and warmth, a place where humans and robots coexisted in harmony. Axiom had become a bridge between worlds, proving that even a creation of metal and wires could discover the essence of being alive.\n",
            "\n",
            "Through its journey, Axiom discovered that emotions were not merely data points but the threads that wove humanity together. And in embracing this truth, it found its own place in the tapestry of life, forever changed by the power of connection."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Multilingual Capabilities\n",
        "\n",
        "One of SUTRA's key strengths is its multilingual support. Let's try it in different languages:"
      ],
      "metadata": {
        "id": "multilingual_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get response in a specific language\n",
        "def get_response_in_language(prompt, language_name):\n",
        "    print(f\"\\nPrompt: {prompt}\")\n",
        "    response = client.chat.completions.create(\n",
        "        model='sutra-v2',\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=1024,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    print(f\"Response ({language_name}): {response.choices[0].message.content}\\n\")\n",
        "\n",
        "# Try different languages\n",
        "get_response_in_language(\"\u0928\u092e\u0938\u094d\u0924\u0947, \u0906\u092a \u0915\u0948\u0938\u0947 \u0939\u0948\u0902?\", \"Hindi\")\n",
        "get_response_in_language(\"\u00bfQu\u00e9 es la inteligencia artificial?\", \"Spanish\")\n",
        "get_response_in_language(\"\u4eba\u5de5\u667a\u80fd\u662f\u4ec0\u4e48\uff1f\", \"Chinese\")\n",
        "get_response_in_language(\"Raconte-moi une courte histoire.\", \"French\")"
      ],
      "metadata": {
        "id": "multilingual_code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d2760f9-bb11-4f15-aa08-62cd39ecd56c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prompt: \u0928\u092e\u0938\u094d\u0924\u0947, \u0906\u092a \u0915\u0948\u0938\u0947 \u0939\u0948\u0902?\n",
            "Response (Hindi): \u0928\u092e\u0938\u094d\u0924\u0947! \u092e\u0948\u0902 \u0920\u0940\u0915 \u0939\u0942\u0901, \u0927\u0928\u094d\u092f\u0935\u093e\u0926\u0964 \u0906\u092a \u0915\u0948\u0938\u0947 \u0939\u0948\u0902?\n",
            "\n",
            "\n",
            "Prompt: \u00bfQu\u00e9 es la inteligencia artificial?\n",
            "Response (Spanish): La inteligencia artificial (IA) es un campo de la inform\u00e1tica que se centra en la creaci\u00f3n de sistemas y programas capaces de realizar tareas que normalmente requieren inteligencia humana. Estas tareas incluyen el reconocimiento de voz, la toma de decisiones, la resoluci\u00f3n de problemas, el aprendizaje autom\u00e1tico y el procesamiento del lenguaje natural, entre otras.\n",
            "\n",
            "Existen diferentes enfoques dentro de la IA, como:\n",
            "\n",
            "1. **IA d\u00e9bil o estrecha**: Sistemas dise\u00f1ados para realizar una tarea espec\u00edfica, como asistentes virtuales (por ejemplo, Siri o Alexa) o algoritmos de recomendaci\u00f3n en plataformas de streaming.\n",
            "\n",
            "2. **IA fuerte o general**: Un concepto te\u00f3rico que se refiere a una IA con capacidad para entender, aprender y aplicar conocimientos de manera similar a un ser humano en una amplia variedad de tareas.\n",
            "\n",
            "3. **Aprendizaje autom\u00e1tico (machine learning)**: Una subdisciplina de la IA que utiliza algoritmos y modelos estad\u00edsticos para permitir que las m\u00e1quinas mejoren su rendimiento en tareas espec\u00edficas a trav\u00e9s de la experiencia y los datos.\n",
            "\n",
            "4. **Redes neuronales**: Modelos inspirados en el funcionamiento del cerebro humano que se utilizan para reconocer patrones y realizar tareas complejas, como el reconocimiento de im\u00e1genes y el procesamiento del lenguaje natural.\n",
            "\n",
            "La IA tiene aplicaciones en diversas \u00e1reas, incluyendo la medicina, la automoci\u00f3n, la educaci\u00f3n, la atenci\u00f3n al cliente, y muchas m\u00e1s, y su desarrollo contin\u00faa evolucionando r\u00e1pidamente.\n",
            "\n",
            "\n",
            "Prompt: \u4eba\u5de5\u667a\u80fd\u662f\u4ec0\u4e48\uff1f\n",
            "Response (Chinese): \u4eba\u5de5\u667a\u80fd\uff08Artificial Intelligence\uff0c\u7b80\u79f0AI\uff09\u662f\u8ba1\u7b97\u673a\u79d1\u5b66\u7684\u4e00\u4e2a\u5206\u652f\uff0c\u65e8\u5728\u521b\u5efa\u80fd\u591f\u6a21\u62df\u4eba\u7c7b\u667a\u80fd\u7684\u7cfb\u7edf\u4e0e\u7a0b\u5e8f\u3002\u8fd9\u4e9b\u7cfb\u7edf\u80fd\u591f\u6267\u884c\u901a\u5e38\u9700\u8981\u4eba\u7c7b\u667a\u6167\u7684\u4efb\u52a1\uff0c\u4f8b\u5982\u5b66\u4e60\u3001\u63a8\u7406\u3001\u95ee\u9898\u89e3\u51b3\u3001\u7406\u89e3\u81ea\u7136\u8bed\u8a00\u3001\u611f\u77e5\u73af\u5883\u4ee5\u53ca\u8fdb\u884c\u51b3\u7b56\u3002\n",
            "\n",
            "\u4eba\u5de5\u667a\u80fd\u53ef\u4ee5\u5206\u4e3a\u4e24\u5927\u7c7b\uff1a\n",
            "\n",
            "1. **\u5f31\u4eba\u5de5\u667a\u80fd\uff08Narrow AI\uff09**\uff1a\u6307\u4e13\u95e8\u7528\u4e8e\u7279\u5b9a\u4efb\u52a1\u7684AI\u7cfb\u7edf\uff0c\u5982\u8bed\u97f3\u8bc6\u522b\u3001\u56fe\u50cf\u8bc6\u522b\u3001\u63a8\u8350\u7cfb\u7edf\u7b49\u3002\u5b83\u4eec\u5728\u7279\u5b9a\u9886\u57df\u5185\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u65e0\u6cd5\u8d85\u51fa\u5176\u8bbe\u8ba1\u7684\u8303\u56f4\u3002\n",
            "\n",
            "2. **\u5f3a\u4eba\u5de5\u667a\u80fd\uff08General AI\uff09**\uff1a\u6307\u5177\u6709\u4e0e\u4eba\u7c7b\u76f8\u4f3c\u7684\u5e7f\u6cdb\u667a\u80fd\u80fd\u529b\u7684AI\u7cfb\u7edf\uff0c\u80fd\u591f\u7406\u89e3\u3001\u5b66\u4e60\u548c\u5e94\u7528\u77e5\u8bc6\u4e8e\u5404\u79cd\u4e0d\u540c\u7684\u4efb\u52a1\u3002\u76ee\u524d\uff0c\u5f3a\u4eba\u5de5\u667a\u80fd\u4ecd\u5904\u4e8e\u7406\u8bba\u9636\u6bb5\uff0c\u5c1a\u672a\u5b9e\u73b0\u3002\n",
            "\n",
            "\u4eba\u5de5\u667a\u80fd\u7684\u5e94\u7528\u9886\u57df\u975e\u5e38\u5e7f\u6cdb\uff0c\u5305\u62ec\u533b\u7597\u3001\u91d1\u878d\u3001\u4ea4\u901a\u3001\u6559\u80b2\u3001\u5a31\u4e50\u7b49\u3002\u5728\u4e0d\u65ad\u53d1\u5c55\u7684\u6280\u672f\u80cc\u666f\u4e0b\uff0cAI\u6b63\u5728\u6539\u53d8\u8bb8\u591a\u884c\u4e1a\u7684\u5de5\u4f5c\u65b9\u5f0f\u548c\u6548\u7387\u3002\n",
            "\n",
            "\n",
            "Prompt: Raconte-moi une courte histoire.\n",
            "Response (French): Il \u00e9tait une fois, dans un petit village nich\u00e9 entre des montagnes verdoyantes, une jeune fille nomm\u00e9e Elara. Elle avait un r\u00eave : d\u00e9couvrir le monde au-del\u00e0 des sommets qui entouraient son foyer. Chaque soir, elle s'asseyait sur une colline, regardant le coucher de soleil, imaginant les aventures qui l'attendaient.\n",
            "\n",
            "Un jour, arm\u00e9e de courage et d'un vieux sac \u00e0 dos, Elara se mit en route. Elle escalada les montagnes, traversa des for\u00eats enchant\u00e9es et rencontra des cr\u00e9atures magiques. Un sage hibou lui montra le chemin vers une vall\u00e9e cach\u00e9e o\u00f9 les fleurs chantaient et les rivi\u00e8res brillaient comme des \u00e9toiles.\n",
            "\n",
            "Dans cette vall\u00e9e, Elara comprit que le v\u00e9ritable voyage ne r\u00e9side pas seulement dans la d\u00e9couverte de nouveaux lieux, mais aussi dans la d\u00e9couverte de soi-m\u00eame. Elle retourna chez elle, le c\u0153ur rempli de souvenirs et de sagesse, pr\u00eate \u00e0 partager ses histoires avec les habitants du village. Ainsi, son r\u00eave de voyager avait \u00e9largi son monde, tout en lui rappelant la beaut\u00e9 de son propre foyer.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Advanced Parameter Tuning\n",
        "\n",
        "Fine-tune your responses with these parameters:"
      ],
      "metadata": {
        "id": "params_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to demonstrate different parameter settings\n",
        "def compare_parameters(prompt):\n",
        "    print(f\"Prompt: {prompt}\\n\")\n",
        "\n",
        "    # Conservative settings (more deterministic)\n",
        "    conservative = client.chat.completions.create(\n",
        "        model='sutra-v2',\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=1024,\n",
        "        temperature=0.3,\n",
        "        top_p=0.85,\n",
        "        frequency_penalty=0.0,\n",
        "        presence_penalty=0.0\n",
        "    )\n",
        "\n",
        "    # Creative settings (more random)\n",
        "    creative = client.chat.completions.create(\n",
        "        model='sutra-v2',\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=1024,\n",
        "        temperature=0.9,\n",
        "        top_p=0.95,\n",
        "        frequency_penalty=0.5,\n",
        "        presence_penalty=0.5\n",
        "    )\n",
        "\n",
        "    print(\"Conservative settings (temperature=0.3):\\n\")\n",
        "    print(conservative.choices[0].message.content)\n",
        "    print(\"\\n---\\n\")\n",
        "    print(\"Creative settings (temperature=0.9):\\n\")\n",
        "    print(creative.choices[0].message.content)\n",
        "\n",
        "# Try with a creative prompt\n",
        "compare_parameters(\"Write a short poem about technology and nature.\")"
      ],
      "metadata": {
        "id": "params_code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e4795b4-8da0-4487-b2cb-00ff30b3cb26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Write a short poem about technology and nature.\n",
            "\n",
            "Conservative settings (temperature=0.3):\n",
            "\n",
            "In circuits bright, where data flows,  \n",
            "A dance of light, where knowledge grows.  \n",
            "Yet in the woods, where whispers play,  \n",
            "Nature's heart beats night and day.  \n",
            "\n",
            "Steel and stone, a city's might,  \n",
            "But stars still shine in velvet night.  \n",
            "A balance sought, in harmony,  \n",
            "Where tech and earth can both be free.  \n",
            "\n",
            "So let us weave, with mindful thread,  \n",
            "A future where both paths are led.  \n",
            "In every byte, and every tree,  \n",
            "A world united, you and me.\n",
            "\n",
            "---\n",
            "\n",
            "Creative settings (temperature=0.9):\n",
            "\n",
            "In the cradle of the forest, whispers hum,  \n",
            "Where circuits pulse and machines softly thrum.  \n",
            "Nature's breath mingles with silicon's sigh,  \n",
            "Underneath the digital sprawl of the sky.  \n",
            "\n",
            "Trees weave shadows while data flows bright,  \n",
            "Stars blink their secrets, illuminating night.  \n",
            "Harmony dances in a delicate blend,  \n",
            "Where wires touch roots, and both hearts mend.  \n",
            "\n",
            "With every heartbeat, a promise to share,  \n",
            "The beauty of both, a world beyond compare.  \n",
            "In this union of life, both ancient and new,  \n",
            "Technology blooms in nature's embrace, true.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Building a Simple Chatbot\n",
        "\n",
        "Create a basic chatbot that maintains conversation history:"
      ],
      "metadata": {
        "id": "chatbot_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_history = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant powered by SUTRA. You are knowledgeable, friendly, and concise.\"}\n",
        "]\n",
        "\n",
        "def chat(user_input):\n",
        "    # Add the user's message to the conversation\n",
        "    conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Get the response from SUTRA\n",
        "    response = client.chat.completions.create(\n",
        "        model='sutra-v2',\n",
        "        messages=conversation_history,\n",
        "        max_tokens=1024,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    # Extract the assistant's reply\n",
        "    assistant_response = response.choices[0].message.content\n",
        "\n",
        "    # Add the assistant's response to the conversation history\n",
        "    conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "\n",
        "    return assistant_response\n",
        "\n",
        "# Interactive chat interface\n",
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "\n",
        "output = widgets.Output()\n",
        "input_box = widgets.Text(placeholder='Type your message here...')\n",
        "\n",
        "def on_send(b):\n",
        "    user_input = input_box.value\n",
        "    input_box.value = ''\n",
        "\n",
        "    with output:\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style='background-color:#ffffff; color:#000000; padding:10px; margin:5px; border-radius:5px;'>\n",
        "            <b>You:</b> {user_input}\n",
        "        </div>\"\"\"))\n",
        "        response = chat(user_input)\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style='background-color:#ffffff; color:#000000; padding:10px; margin:5px; border-radius:5px;'>\n",
        "            <b>SUTRA:</b> {response}\n",
        "        </div>\"\"\"))\n",
        "\n",
        "send_button = widgets.Button(description=\"Send\")\n",
        "send_button.on_click(on_send)\n",
        "\n",
        "def on_enter(widget):\n",
        "    on_send(None)\n",
        "\n",
        "input_box.on_submit(on_enter)\n",
        "\n",
        "display(HTML(\"<h3>Chat with SUTRA</h3>\"))\n",
        "display(widgets.VBox([output, widgets.HBox([input_box, send_button])]))"
      ],
      "metadata": {
        "id": "chatbot_code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264,
          "referenced_widgets": [
            "24378468f6304949af8e3221e91cd677",
            "0f063e4b3d11407c91f3fc73a00f02f7",
            "e5fc753c81bc4f49b792d739bec7dd3c",
            "84538336567941d7bd820ccef2278cf8",
            "41b76041263d4a7eb5457b10820b9d8f",
            "ac354aa1cf2f4ca9b5563d9059063a78",
            "b36ab2af89d9407aafd585b73f617271",
            "14e3a174c1b240e6bde20759955671e7",
            "130eac94efa1402a97a1412d9e2a25bf",
            "58b5631e04ef48e48f3c55e44454480e",
            "2ed550bf1b274bdb9807315f50b5fbc3",
            "5fffca1a50194186b1e8b977457dc429"
          ]
        },
        "outputId": "74613f29-7c91-4a74-d523-d893debb9e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h3>Chat with SUTRA</h3>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Output(), HBox(children=(Text(value='', placeholder='Type your message here...'), Button(descri\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24378468f6304949af8e3221e91cd677"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Integration with LangChain\n",
        "\n",
        "For more complex applications, you can integrate SUTRA with LangChain:"
      ],
      "metadata": {
        "id": "langchain_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install LangChain\n",
        "!pip install -qU langchain langchain-openai langchain_community\n",
        "print(\"\u2705 LangChain installed successfully!\")"
      ],
      "metadata": {
        "id": "langchain_install",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a121fb1e-3beb-4ed7-c7ea-f6b9a36f52de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.5/2.5 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/44.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u2705 LangChain installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "\n",
        "# Initialize the LangChain ChatOpenAI with SUTRA\n",
        "chat = ChatOpenAI(\n",
        "    model=\"sutra-v2\",\n",
        "    api_key=api_key,  # Use your actual API key\n",
        "    base_url=\"https://api.two.ai/v2\"\n",
        ")\n",
        "\n",
        "# Define messages\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant that provides concise answers.\"),\n",
        "    HumanMessage(content=\"Tell me a joke about programming.\")\n",
        "]\n",
        "\n",
        "# Get and print the response\n",
        "response = chat.invoke(messages)\n",
        "print(\"LangChain + SUTRA response:\\n\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "langchain_code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca21d45-cfbc-4759-ec68-0932277a46fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangChain + SUTRA response:\n",
            "\n",
            "Why do programmers prefer dark mode?\n",
            "\n",
            "Because light attracts bugs!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Troubleshooting\n",
        "\n",
        "If you encounter issues:\n",
        "\n",
        "1. **Authentication Errors**: Verify your API key is correct and properly set\n",
        "2. **Rate Limiting**: Check if you've exceeded your API usage limits\n",
        "3. **Connection Issues**: Ensure you have internet connectivity and the API endpoint is accessible\n",
        "4. **Response Format**: Make sure you're correctly parsing the response object\n",
        "\n",
        "\n",
        "## Resources\n",
        "\n",
        "- [Official Documentation](https://docs.two.ai/version-2/docs/get-started-with-sutra)\n",
        "- [TWO AI Website](https://www.two.ai)\n",
        "- [Follow TWO AI on Twitter](https://twitter.com/two_platforms)\n",
        "\n",
        "---\n",
        "\n",
        "\u00a9 2025 TWO AI | All Rights Reserved"
      ],
      "metadata": {
        "id": "conclusion_cell"
      }
    }
  ]
}